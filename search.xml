<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[mariadb 内存占用优化]]></title>
    <url>%2Fmariadb-better%2F</url>
    <content type="text"><![CDATA[摘要：我们在使用mariadb的时候发现有时候不能启动起来，在使用过程中mariadb占用的内存很大，在这里学习下mariadb与内存相关的配置项，对mariadb进行调优。查询最高内存占用使用以下命令可以知道mysql的配置使用多少 RAM1234567891011121314SELECT ( @@key_buffer_size+ @@query_cache_size+ @@innodb_buffer_pool_size+ @@innodb_additional_mem_pool_size+ @@innodb_log_buffer_size+ @@max_connections * ( @@read_buffer_size+ @@read_rnd_buffer_size+ @@sort_buffer_size+ @@join_buffer_size+ @@binlog_cache_size+ @@thread_stack+ @@tmp_table_size)) / (1024 * 1024 * 1024) AS MAX_MEMORY_GB;可以使用mysql计算器来计算内存使用下面是理论，可以直接到推荐配置如何调整配置key_buffer_size（MyISAM索引用）指定索引缓冲区的大小，它决定索引处理的速度，尤其是索引读的速度。为了最小化磁盘的 I/O ， MyISAM 存储引擎的表使用键高速缓存来缓存索引，这个键高速缓存的大小则通过 key-buffer-size 参数来设置。如果应用系统中使用的表以 MyISAM 存储引擎为主，则应该适当增加该参数的值，以便尽可能的缓存索引，提高访问的速度。怎么设12345678show global status like 'key_read%';+------------------------+-------------+| Variable_name | Value |+------------------------+-------------+| Key_read_requests | 27813678764 || Key_reads | 6798830 |---------------------key_buffer_size通过检查状态值Key_read_requests和Key_reads，可以知道key_buffer_size设置是否合理。比例key_reads / key_read_requests应该尽可能的低，至少是1:100，1:1000更好。1show global status like '%created_tmp_disk_tables%';key_buffer_size只对MyISAM表起作用。即使你不使用MyISAM表，但是内部的临时磁盘表是MyISAM表，也要使用该值。可以使用检查状态值created_tmp_disk_tables得知详情。对于1G内存的机器，如果不使用MyISAM表，推荐值是16M（8-64M）另一个参考如下1234567show global status like 'key_blocks_u%';+------------------------+-------------+| Variable_name | Value |+------------------------+-------------+| Key_blocks_unused | 0 || Key_blocks_used | 413543 |+------------------------+-------------+Key_blocks_unused表示未使用的缓存簇(blocks)数，Key_blocks_used表示曾经用到的最大的blocks数，比如这台服务器，所有的缓存都用到了，要么增加key_buffer_size，要么就是过渡索引了，把缓存占满了。比较理想的设置：可以根据此工式来动态的调整Key_blocks_used / (Key_blocks_unused + Key_blocks_used) * 100% ≈ 80%1show engines;查询存储引擎innodb_buffer_pool_size （innodb索引用）这个参数和MyISAM的key_buffer_size有相似之处，但也是有差别的。这个参数主要缓存innodb表的索引，数据，插入数据时的缓冲。为Innodb加速优化首要参数。该参数分配内存的原则：这个参数默认分配只有8M，可以说是非常小的一个值。如果是专用的DB服务器，且以InnoDB引擎为主的场景，通常可设置物理内存的50%，这个参数不能动态更改，所以分配需多考虑。分配过大，会使Swap占用过多，致使Mysql的查询特慢。如果是非专用DB服务器，可以先尝试设置成内存的1/4，如果有问题再调整query_cache_size（查询缓存）缓存机制简单的说就是缓存sql文本及查询结果，如果运行相同的sql，服务器直接从缓存中取到结果，而不需要再去解析和执行sql。如果表更改了，那么使用这个表的所有缓冲查询将不再有效，查询缓存值的相关条目被清空。更改指的是表中任何数据或是结构的改变，包括INSERT、UPDATE、DELETE、TRUNCATE、ALTER TABLE、DROP TABLE或DROP DATABASE等，也包括那些映射到改变了的表的使用MERGE表的查询。显然，这对于频繁更新的表，查询缓存是不适合的，而对于一些不常改变数据且有大量相同sql查询的表，查询缓存会节约很大的性能。注意：如果你查询的表更新比较频繁，而且很少有相同的查询，最好不要使用查询缓存。因为这样会消耗很大的系统性能还没有任何的效果要不要打开？先设置成这样跑一段时间12query_cache_size=128M query_cache_type=1看看命中结果来进行进一步的判断1234567891011121314mysql&gt; show status like '%Qcache%';+-------------------------+-----------+| Variable_name | Value |+-------------------------+-----------+| Qcache_free_blocks | 669 || Qcache_free_memory | 132519160 || Qcache_hits | 1158 || Qcache_inserts | 284824 || Qcache_lowmem_prunes | 2741 || Qcache_not_cached | 1755767 || Qcache_queries_in_cache | 579 || Qcache_total_blocks | 1853 |+-------------------------+-----------+8 rows in set (0.00 sec)Qcache_free_blocks:表示查询缓存中目前还有多少剩余的blocks，如果该值显示较大，则说明查询缓存中的内存碎片过多了，可能在一定的时间进行整理。Qcache_free_memory:查询缓存的内存大小，通过这个参数可以很清晰的知道当前系统的查询内存是否够用，是多了，还是不够用，DBA可以根据实际情况做出调整。Qcache_hits:表示有多少次命中缓存。我们主要可以通过该值来验证我们的查询缓存的效果。数字越大，缓存效果越理想。Qcache_inserts: 表示多少次未命中然后插入，意思是新来的SQL请求在缓存中未找到，不得不执行查询处理，执行查询处理后把结果insert到查询缓存中。这样的情况的次数，次数越多，表示查询缓存应用到的比较少，效果也就不理想。当然系统刚启动后，查询缓存是空的，这很正常。Qcache_lowmem_prunes:该参数记录有多少条查询因为内存不足而被移除出查询缓存。通过这个值，用户可以适当的调整缓存大小。Qcache_not_cached: 表示因为query_cache_type的设置而没有被缓存的查询数量。Qcache_queries_in_cache:当前缓存中缓存的查询数量。Qcache_total_blocks:当前缓存的block数量。我们可以看到现网命中1158，未缓存的有1755767次，说明我们这个系统命中的太少了，表变动比较多，不什么开启这个功能涉及参数query_cache_limit：允许 Cache 的单条 Query 结果集的最大容量，默认是1MB，超过此参数设置的 Query 结果集将不会被 Cachequery_cache_min_res_unit：设置 Query Cache 中每次分配内存的最小空间大小，也就是每个 Query 的 Cache 最小占用的内存空间大小query_cache_size：设置 Query Cache 所使用的内存大小，默认值为0，大小必须是1024的整数倍，如果不是整数倍，MySQL 会自动调整降低最小量以达到1024的倍数query_cache_type：控制 Query Cache 功能的开关，可以设置为0(OFF),1(ON)和2(DEMAND)三种，意义分别如下：0(OFF)：关闭 Query Cache 功能，任何情况下都不会使用 Query Cache1(ON)：开启 Query Cache 功能，但是当 SELECT 语句中使用的 SQL_NO_CACHE 提示后，将不使用Query Cache2(DEMAND)：开启 Query Cache 功能，但是只有当 SELECT 语句中使用了 SQL_CACHE 提示后，才使用 Query Cachequery_cache_wlock_invalidate：控制当有写锁定发生在表上的时刻是否先失效该表相关的 Query Cache，如果设置为 1(TRUE)，则在写锁定的同时将失效该表相关的所有 Query Cache，如果设置为0(FALSE)则在锁定时刻仍然允许读取该表相关的 Query Cache。innodb_additional_mem_pool_size（InnoDB内部目录大小）InnoDB 字典信息缓存主要用来存放 InnoDB 存储引擎的字典信息以及一些 internal 的共享数据结构信息，也就是存放Innodb的内部目录，所以其大小也与系统中所使用的 InnoDB 存储引擎表的数量有较大关系。这个值不用分配太大，通常设置16Ｍ够用了，默认8M，如果设置的内存大小不够，InnoDB 会自动申请更多的内存，并在 MySQL 的 Error Log 中记录警告信息。innodb_log_buffer_size （日志缓冲）表示InnoDB写入到磁盘上的日志文件时使用的缓冲区的字节数，默认值为16M。一个大的日志缓冲区允许大量的事务在提交之前不用写日志到磁盘，所以如果有更新，插入或删除许多行的事务，则使日志缓冲区更大一些可以节省磁盘IO通常最大设为64M足够max_connections (最大并发连接)MySQL的max_connections参数用来设置最大连接（用户）数。每个连接MySQL的用户均算作一个连接，max_connections的默认值为100。这个参数实际起作用的最大值（实际最大可连接数）为16384，即该参数最大值不能超过16384，即使超过也以16384为准；增加max_connections参数的值，不会占用太多系统资源。系统资源（CPU、内存）的占用主要取决于查询的密度、效率等；该参数设置过小的最明显特征是出现”Too many connections”错误1234567891011121314151617181920mysql&gt; show variables like '%max_connect%';+-----------------------+-------+| Variable_name | Value |+-----------------------+-------+| extra_max_connections | 1 || max_connect_errors | 100 || max_connections | 2048 |+-----------------------+-------+3 rows in set (0.00 sec)mysql&gt; show status like 'Threads%';+-------------------+---------+| Variable_name | Value |+-------------------+---------+| Threads_cached | 0 || Threads_connected | 1 || Threads_created | 9626717 || Threads_running | 1 |+-------------------+---------+4 rows in set (0.00 sec)可以看到此时的并发数也就是Threads_connected=1，还远远达不到20481234567mysql&gt; show variables like 'open_files_limit';+------------------+-------+| Variable_name | Value |+------------------+-------+| open_files_limit | 65535 |+------------------+-------+1 row in set (0.00 sec)max_connections 还取决于操作系统对单进程允许打开最大文件数的限制也就是说如果操作系统限制单个进程最大可以打开100个文件那么 max_connections 设置为200也没什么用MySQL 的 open_files_limit 参数值是在MySQL启动时记录的操作系统对单进程打开最大文件数限制的值可以使用 show variables like ‘open_files_limit’; 查看 open_files_limit 值12ulimit -n65535或者直接在 Linux 下通过ulimit -n命令查看操作系统对单进程打开最大文件数限制 ( 默认为1024 )connection级内存参数(线程独享)connection级参数，是在每个connection第一次需要使用这个buffer的时候，一次性分配设置的内存。排序性能mysql对于排序,使用了两个变量来控制sort_buffer_size和 max_length_for_sort_data, 不象oracle使用SGA控制. 这种方式的缺点是要单独控制,容易出现排序性能问题.1234567891011mysql&gt; SHOW GLOBAL STATUS like '%sort%';+---------------------------+--------+| Variable_name | Value |+---------------------------+--------+| Sort_merge_passes | 0 || Sort_priority_queue_sorts | 1409 || Sort_range | 0 || Sort_rows | 843479 || Sort_scan | 13053 |+---------------------------+--------+5 rows in set (0.00 sec)如果发现Sort_merge_passes的值比较大，你可以考虑增加sort_buffer_size 来加速ORDER BY 或者GROUP BY 操作,不能通过查询或者索引优化的。我们这为0，那就没必要设置那么大。读取缓存read_buffer_size = 128K(默认128K)为需要全表扫描的MYISAM数据表线程指定缓存read_rnd_buffer_size = 4M：(默认256K)首先，该变量可以被任何存储引擎使用，当从一个已经排序的键值表中读取行时，会先从该缓冲区中获取而不再从磁盘上获取。大事务binlog12345678mysql&gt; show global status like 'binlog_cache%';+-----------------------+----------+| Variable_name | Value |+-----------------------+----------+| Binlog_cache_disk_use | 220840 || Binlog_cache_use | 67604667 |+-----------------------+----------+2 rows in set (0.00 sec)Binlog_cache_disk_use表示因为我们binlog_cache_size设计的内存不足导致缓存二进制日志用到了临时文件的次数Binlog_cache_use 表示 用binlog_cache_size缓存的次数当对应的Binlog_cache_disk_use 值比较大的时候 我们可以考虑适当的调高 binlog_cache_size 对应的值如上图，现网是32K，我们加到64Kjoin语句内存影响如果应用中，很少出现join语句，则可以不用太在乎join_buffer_size参数的设置大小。如果join语句不是很少的话，个人建议可以适当增大join_buffer_size到1MB左右，如果内存充足可以设置为2MB。线程内存影响Thread_stack：每个连接线程被创建时，MySQL给它分配的内存大小。当MySQL创建一个新的连接线程时，需要给它分配一定大小的内存堆栈空间，以便存放客户端的请求的Query及自身的各种状态和处理信息。12345678910111213141516171819202122mysql&gt; show status like '%threads%';+-------------------------+---------+| Variable_name | Value |+-------------------------+---------+| Delayed_insert_threads | 0 || Slow_launch_threads | 0 || Threadpool_idle_threads | 0 || Threadpool_threads | 0 || Threads_cached | 0 || Threads_connected | 1 || Threads_created | 9649301 || Threads_running | 1 |+-------------------------+---------+8 rows in set (0.00 sec)mysql&gt; show status like 'connections';+---------------+---------+| Variable_name | Value |+---------------+---------+| Connections | 9649311 |+---------------+---------+1 row in set (0.00 sec)如上：系统启动到现在共接受到客户端的连接9649311次，共创建了9649301个连接线程，当前有1个连接线程处于和客户端连接的状态。而在Thread Cache池中共缓存了0个连接线程(Threads_cached)。Thread Cache 命中率：1Thread_Cache_Hit = (Connections - Threads_created) / Connections * 100%;一般在系统稳定运行一段时间后，Thread Cache命中率应该保持在90%左右才算正常。内存临时表tmp_table_size 控制内存临时表的最大值,超过限值后就往硬盘写，写的位置由变量 tmpdir 决定max_heap_table_size 用户可以创建的内存表(memory table)的大小.这个值用来计算内存表的最大行数值。Order By 或者Group By操作多的话，加大这两个值，默认16M123456789mysql&gt; show status like 'Created_tmp_%';+-------------------------+-------+| Variable_name | Value |+-------------------------+-------+| Created_tmp_disk_tables | 0 || Created_tmp_files | 626 || Created_tmp_tables | 3 |+-------------------------+-------+3 rows in set (0.00 sec)如上图，写入硬盘的为0，3次中间表，说明我们的默认值足够用了mariadb 推荐配置注意这里只推荐innodb引擎12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455[mysqld]datadir=/var/lib/mysqlsocket=/var/lib/mysql/mysql.sockdefault-storage-engine=MYISAMcharacter-set-server=utf8collation-server=utf8_general_ciuser=mysqlsymbolic-links=0# global settingstable_cache=65535table_definition_cache=65535max_allowed_packet=4Mnet_buffer_length=1Mbulk_insert_buffer_size=16Mquery_cache_type=0 #是否使用查询缓冲,0关闭query_cache_size=0 #0关闭，因为改表操作多，命中低，开启消耗cpu# sharedkey_buffer_size=8M #保持8M MyISAM索引用innodb_buffer_pool_size=4G #DB专用mem*50%，非DB专用mem*15%到25%myisam_sort_buffer_size=32Mmax_heap_table_size=16M #最大中间表大小tmp_table_size=16M #中间表大小# per-threadsort_buffer_size=256K #加速排序缓存大小read_buffer_size=128k #为需要全表扫描的MYISAM数据表线程指定缓存read_rnd_buffer_size=4M #已排序的表读取时缓存，如果比较大内存就到6Mjoin_buffer_size=1M #join语句多时加大，1-2Mthread_stack=256k #线程空间，256K or 512Kbinlog_cache_size=64K #大事务binlog# big-tablesinnodb_file_per_table = 1skip-external-lockingmax_connections=2048 #最大连接数skip-name-resolve# slow_query_logslow_query_log_file = /var/log/mysql-slow.loglong_query_time = 30group_concat_max_len=65536# according to tuning-primer.shthread_cache_size = 8thread_concurrency = 16# set variablesconcurrent_insert=2运行时修改1set global &#123;要改的key&#125; = &#123;值&#125;; （立即生效重启后失效）引用记一次Mysql占用内存过高的优化过程mysql 优化技巧心得一(key_buffer_size设置)mysql内存计算mysql计算器mariadb官网]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vimdiff]]></title>
    <url>%2Fvimdiff%2F</url>
    <content type="text"><![CDATA[摘要：我们在windows平台上用过beyond compare来进行文件比较，在linux平台上也有类似的东西，还是免费的。那就是vimdiff，它是vim的diff模式，依赖于diff命令。在文件比较方便比diff要强大的多，它有简单明了的界面以及对比结果一目了然的特点，容易对多处差异进行对比和合并。启动方法保证安装了vim和diff命令使用以下方法启动12vimdiff file1 file2 #垂直vimdiff -o file1 file2 #水平切换视角12345Ctrl-w w #在不同窗口间跳转Ctrl-w K #把当前窗口移到最上边Ctrl-w H #把当前窗口移到最左边Ctrl-w J #把当前窗口移到最下边Ctrl-w L #把当前窗口移到最右边其中K和J两个操作会把窗口改成水平分割方式。对比差异只在某一文件中存在的行的背景色被设置为蓝色，而在另一文件中的对应位置被显示为绿色。两个文件中都存在，但是包含差异的行显示为粉色背景，引起差异的文字用红色背景加以突出。+-- 7 lines: #include &lt;stdio.h&gt;------------------- 表示折叠的行 可以用zo（open）可以把折叠的行打开,使用zc(close)可以把折叠的行关闭------------------------------------------- 表示删除的行上下文的展开和查看：比较和合并文件的时候经常需要结合上下文来确定最终要采取的操作。Vimdiff 缺省是会把不同之处上下各 6 行的文本都显示出来以供参考。其他的相同的文本行被自动折叠。如果希望修改缺省的上下文行数，可以这样设置(设置上下文为3行)：1:set diffopt=context:3光标可以使用快捷键在各个差异点之间快速移动。]c 跳转到下一个差异点[c 跳转到上一个差异点2]c如果在命令前加上数字的话，可以跳过一个或数个差异点，从而实现跳的更远。比如如果在位于第一个差异点的行输入2]c，将越过下一个差异点，跳转到第三个差异点。合并用到的命令：dp （diff “put”）如果希望把另一个文件的内容复制到当前行中，可以使用命令do (diff “get”，之所以不用dg，是因为dg已经被另一个命令占用了):diffupdate 在修改一个或两个文件之后，vimdiff会试图自动来重新比较文件，来实时反映比较结果。但是也会有处理失败的情况，这个时候需要手工来刷新比较结果&lt;ESC&gt;, u 如果希望撤销修改，可以和平常用vim编辑一样，直接但是要注意一定要将光标移动到需要撤销修改的文件窗口中。备注： 如果有多个窗口的话只要在dp、do命令前加数字代表把当前行复制到哪个窗口中或者把哪个窗口中的复制到当前窗口引用vimdiff的常用命令技巧：Vimdiff 使用]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>工具</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用腾讯云服务器搭建vpn]]></title>
    <url>%2Fcreate_vpn%2F</url>
    <content type="text"><![CDATA[摘要：最近腾讯云发了优惠券那就给自己搭建一个vpn吧，便于随时上外网。服务器环境腾讯云centos7.2 64位服务器上配置首先查看系统是否支持pptpd服务：1modprobe ppp-compress-18 &amp;&amp; echo yes安装ppp , pptpd，iptables123yum install -y ppp pptpd iptablessystemctl mask firewalldsystemctl stop firewalld修改配制123vim /etc/pptpd.conf #找到配制文件中默认的值，去掉注释即可localip 192.168.0.2-238,192.168.0.245remoteip 192.168.1.2-238,192.168.1.245需要注意的是：remoteip最好不用和VPN client本身所在的局域网的ip冲突。修改DNS123vim /etc/ppp/options.pptpd #末尾添加dnsms-dns 8.8.8.8ms-dns 114.114.114.114添加vpn账户123vim /etc/ppp/chap-secrets# client server secret IP addresses user pptpd passwd *开启路由转发123vim /etc/sysctl.confnet.ipv4.ip_forward = 1 #添加在配制文件的末尾即可sysctl -p #运行这个命令会输出上面添加的那一行信息，意思是使内核修改生效在防火墙上开启nat转发1iptables -t nat -A POSTROUTING -s 192.168.0.0/24 -o eth0 -j MASQUERADE #IP和网口根据实际情况修改即可开启服务123service iptables save #正常来说要做这个来使iptables生效systemctl restart iptablessystemctl restart pptpd检查是否成功12netstat -anlpt | grep pptptcp 0 0 0.0.0.0:1723 0.0.0.0:* LISTEN 27202/pptpd如果不能访问的话，看系统日志位置安全组加一个入站规则手机上连接手机上找到vpn新建，pptp协议服务器ip: 你的服务器ip用户名：你刚刚设置的用户名/etc/ppp/chap-secrets下密码: 你刚刚设置的密码/etc/ppp/chap-secrets下mac上连接我发现新的MacOS不支持PPTP协议，先用shimo，等试用期到了再看要不要加L2TP]]></content>
      <categories>
        <category>vpn</category>
      </categories>
      <tags>
        <tag>vpn</tag>
        <tag>PPTP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[base64]]></title>
    <url>%2Fbase64%2F</url>
    <content type="text"><![CDATA[欢迎来到我的博客, 请输入密码来访问这篇文章. Incorrect Password! No content to display! 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]]></content>
      <categories>
        <category>base64</category>
      </categories>
      <tags>
        <tag>base64</tag>
        <tag>编码</tag>
        <tag>加密</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[版本控制工具——Git常用命令]]></title>
    <url>%2Fgit-start2%2F</url>
    <content type="text"><![CDATA[摘要：我们说过了git的几乎全部的常用情况，相信基本已经可以在平时团队协作开发的过程中游刃有余了。我熟悉了git的使用以后，这里给出git常用的命令，以下的命令几乎覆盖了所有的git常用操作，在此记录便于快速查找使用。配置相关123456789101112131415161718git init # 初始化本地git仓库（创建新仓库）git config --global user.name "xxx" # 配置用户名git config --global user.email "xxx@xxx.com" # 配置邮件// git status等命令自动着色git config --global color.ui true git config --global color.status autogit config --global color.diff autogit config --global color.branch autogit config --global color.interactive auto// 查看当前代理设置git config --global http.proxy// 设置当前代理为 http://127.0.0.1:1080 或 socket5://127.0.0.1:1080git config --global http.proxy 'http://127.0.0.1:1080'git config --global https.proxy 'http://127.0.0.1:1080'git config --global http.proxy 'socks5://127.0.0.1:1080'git config --global https.proxy 'socks5://127.0.0.1:1080' git config --global --unset http.proxy #删除 proxy git config代码文件与提交相关1234567891011121314151617181920git status # 查看当前版本状态（是否修改）git add xyz # 添加xyz文件至indexgit add . # 增加当前子目录下所有更改过的文件至indexgit commit -m 'xxx' # 提交git commit --amend -m 'xxx' # 合并上一次提交（用于反复修改）git commit -am 'xxx' # 将add和commit合为一步git rm xxx # 删除index中的文件git rm -r * # 递归删除git log # 显示提交日志git log -1 # 显示1行日志 -n为n行git log -5git log --stat # 显示提交日志及相关变动文件git log -p -mgit log -- filename # 查看文件的修改日志 git show dfb02e6e4f2f7b573337763e5c0013802e392818 # 显示某个提交的详细内容git show dfb02 # 可只用commitid的前几位git show HEAD # 显示HEAD提交日志git show HEAD^ # 显示HEAD的父（上一个版本）的提交日志 ^^为上两个版本 ^5为上5个版本git whatchanged # 显示提交历史对应的文件修改git revert dfb02e6e4f2f7b573337763e5c0013802e392818 # 撤销提交dfb02e6e4f2f7b573337763e5c0013802e392818tag相关1234567git tag # 显示已存在的taggit tag -a v2.0 -m 'xxx' # 增加v2.0的taggit show v2.0 # 显示v2.0的日志及详细内容git log v2.0 # 显示v2.0的日志git push --tags # 把所有tag推送到远程仓库git tag -d tag_name # 本地删除名为tag_name的taggit push origin :refs/tags/tag_name # 远程删除名为tag_name的tag差异比较相关123456git diff # 显示所有未添加至index的变更git diff --cached # 显示所有已添加index但还未commit的变更git diff HEAD^ # 比较与上一个版本的差异git diff HEAD -- ./lib # 比较与HEAD版本lib目录的差异git diff origin/master..master # 比较远程分支master上有本地分支master上没有的git diff origin/master..master --stat # 只显示差异的文件，不显示具体内容分支相关12345678910111213141516171819202122232425262728293031git clone git+ssh://git@192.168.53.168/VT.git # clone远程仓库git remote add origin git+ssh://git@192.168.53.168/VT.git # 增加远程定义（用于push/pull/fetch）git branch # 显示本地分支git branch --contains 50089 # 显示包含提交50089的分支git branch -a # 显示所有分支git branch -r # 显示所有原创分支git branch --merged # 显示所有已合并到当前分支的分支git branch --no-merged # 显示所有未合并到当前分支的分支git branch -m master master_copy # 本地分支改名git checkout -b master_copy # 从当前分支创建新分支master_copy并检出git checkout -b master master_copy # 上面的完整版git checkout features/performance # 检出已存在的features/performance分支git checkout --track hotfixes/BJVEP933 # 检出远程分支hotfixes/BJVEP933并创建本地跟踪分支git checkout v2.0 # 检出版本v2.0git checkout -b devel origin/develop # 从远程分支develop创建新本地分支devel并检出git checkout -- README # 检出head版本的README文件（可用于修改错误回退）git merge origin/master # 合并远程master分支至当前分支git cherry-pick ff44785404a8e # 合并提交ff44785404a8e的修改git push origin master # 将当前分支push到远程master分支git push origin :hotfixes/BJVEP933 # 删除远程仓库的hotfixes/BJVEP933分支git fetch # 获取所有远程分支（不更新本地分支，另需merge）git fetch --prune # 获取所有原创分支并清除服务器上已删掉的分支git pull origin master # 获取远程分支master并merge到当前分支git mv README README2 # 重命名文件README为README2git reset --hard HEAD # 将当前版本重置为HEAD（通常用于merge失败回退）git rebasegit branch -d hotfixes/BJVEP933 # 删除分支hotfixes/BJVEP933（本分支修改已合并到其他分支）git branch -D hotfixes/BJVEP933 # 强制删除分支hotfixes/BJVEP933，小心操作git ls-files # 列出git index包含的文件git show-branch # 图示当前分支历史git show-branch --all # 图示所有分支历史图示命令123456789git ls-tree HEAD # 内部命令：显示某个git对象git rev-parse v2.0 # 内部命令：显示某个ref对于的SHA1 HASHgit reflog # 显示所有提交，包括孤立节点git show HEAD@&#123;5&#125;git show master@&#123;yesterday&#125; # 显示master分支昨天的状态git log --pretty=format:'%h %s' --graph # 图示提交日志git show HEAD~3git show -s --pretty=raw 2be7fcb476暂存相关1234git stash # 暂存当前修改，将所有至为HEAD状态git stash list # 查看所有暂存git stash show -p stash@&#123;0&#125; # 参考第一次暂存git stash apply stash@&#123;0&#125; # 应用第一次暂存查找12git grep "delete from" #查找当前分支下的文件内容，可以git grep --help看具体用法 git grep "delete from" v2.0 #指定tag来查找git index操作1234git update-index —assume-unchanged 文件名 #取消本地跟踪git update-index —no-assume-unchanged 文件名 #恢复本地跟踪git ls-files -v| grep '^h\ ' #可以看到本地不跟踪的文件注意事项理论上，git日常用到的命令是 diff show fetch rebase pull push checkout commit status 等，这些命令都不会导致代码丢失，假如害怕代码丢失，可以预先commit一次，再进行修改，但切记不可使用自己不熟悉的命令任何命令，不要加上-f的强制参数，否则可能导致代码丢失建议多使用命令行，不要使用图形界面操作引用git官网廖雪峰的官方网站-git篇hexo博客部署到vps]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>工具</tag>
        <tag>版本控制</tag>
        <tag>git教程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[版本控制工具——Git常用操作（下）]]></title>
    <url>%2Fgit-start3%2F</url>
    <content type="text"><![CDATA[摘要：上一集我们一起入门学习了git的基本概念和git常用的操作，包括提交和同步代码、使用分支、出现代码冲突的解决办法、紧急保存现场和恢复现场的操作。学会以后已经足够我们使用Git参加协作开发了，但是在开发的过程中难免会出错，本文主要介绍版本控制的过程中出错了的场景，以及Git开发的一些技巧，让我们用的更流畅。上集回顾：Git的基本概念一个人使用Git时的代码版本控制–（提交、拉代码、分支操作）多人合作时的代码版本控制–（合并冲突、暂存代码）上集传送门：版本控制工具——Git常用操作（上）本文核心：后悔药-各种后悔操作（撤消commit,回滚，回退远程仓库等）哎呀，提交的时候漏了文件tag操作git忽略不想提交的文件后悔药撤消当前commit如果你发现刚刚的操作一不小心commit了，所幸你还没有推送到远程仓库，你可以用reset命令来撤消你的这次提交。reset命令的作用：重置HEAD(当前分支的版本顶端）到另外一个commit。我们的撤消当前提交的时候往往不希望我们此次提交的代码发生任何丢失，只是撤消掉commit的操作，以便我们继续修改文件。如果我们是想直接不要了这次commit的全部内容的任何修改我们将在下一小节讨论。来，我们先说一句蠢话来diss老板12345678910111213141516171819$ touch to_boss.txt$ echo 'my boss is a bad guy!' &gt; to_boss.txt$ git add to_boss.txt$ git statusOn branch masterYour branch is up to date with 'origin/master'.Changes to be committed: (use "git reset HEAD &lt;file&gt;..." to unstage) new file: to_boss.txt$ git commit -m "[+]骂了我的boss"[master 3d113a7] [+]骂了我的boss 1 file changed, 1 insertion(+) create mode 100644 to_boss.txt创建to_boss.txt文件，并向其写入了my boss is a bad guy!add然后status查看新文件已经加入跟踪commit提交了这次的修改好了，刚刚我们“不小心”diss了我们的老板，要是被发现就完了，所幸还没有push，要快点撤消这些提交，再换成一些好话才行。我们使用以下命令：123456789101112131415161718192021222324252627282930313233343536373839$ git reset --soft head^$ git statusOn branch masterYour branch is behind 'origin/master' by 1 commit, and can be fast-forwarded. (use "git pull" to update your local branch)Changes to be committed: (use "git reset HEAD &lt;file&gt;..." to unstage) new file: to_boss.txt$ cat to_boss.txtmy boss is a bad guy!$ echo 'my boss is a good boy!'my boss is a good boy!$ echo 'my boss is a good boy!' &gt; to_boss.txt$ cat to_boss.txtmy boss is a good boy!$ git add to_boss.txt$ git statusOn branch masterYour branch is behind 'origin/master' by 1 commit, and can be fast-forwarded. (use "git pull" to update your local branch)Changes to be committed: (use "git reset HEAD &lt;file&gt;..." to unstage) new file: to_boss.txt $ git commit -m "[*]夸了我的boss"[master 8be46aa] [*]夸了我的boss 1 file changed, 1 insertion(+) create mode 100644 to_boss.txtgit reset --soft head^撤消了本次提交，将工作区恢复到了提交前但是已经add的状态将to_boss.txt的内容改成了my boss is a good boy!add然后commit提交好了，有惊无险，这就是撤消commit的操作。另一种情况是如果你想撤消commit的时候支持舍弃这次全部的修改就把git reset --soft head^改成git reset --hard head^，这样你本地修改就彻底丢掉了(慎用)，如果真用了想找回来怎么办？见救命的后悔药。当然了，你只要开心不加soft或hard参数也是安全的(相当于使用了--mixed参数)，只不过是撤消以后你的本次修改就会回到add之前的状态，你可以重新检视然后再做修改和commit。回退远程仓库要是我们做的更过分一点，直接把这次commit直接给push怎么办？要是被发现就全完了,我们来看看github上的远程仓库。完了，真的提交了（我刚刚push的）让我们冷静下来，用撤消当前commit的方法先撤消本地的commit,这次我们来试试用hard参数来撤消1234567891011121314$ git reset --hard head^HEAD is now at 3f22a06 [+]add file time.txt$ git statusOn branch masterYour branch is behind 'origin/master' by 1 commit, and can be fast-forwarded. (use "git pull" to update your local branch)nothing to commit, working tree clean$ git push origin master --forceTotal 0 (delta 0), reused 0 (delta 0)To github.com:pzqu/git_test.git + 3d113a7...3f22a06 master -&gt; master (forced update)使用git reset --hard head^回滚到上一个commit使用git status查看现在的工作区情况，提示Your branch is behind &#39;origin/master&#39; by 1 commit,代表成功表了上一次的提示状态，nothing to commit, working tree clean代表这次的修改全没了，清理的算是一个彻底。如果还想找回来怎么办，我们还真是有办法让你找回来的，见救命的后悔药。git push origin master --force 命令强制提交到远程仓库(注意，如果是在团队合作的情况下，不到迫不得已不要给命令加–force参数)让我们看看github真的撤消了远程仓库，长舒一口气。暂存区（Stage）到工作区（Working Directory）如果我们刚刚执行了git reset --soft或者add等的操作，把一些东西加到了我们的暂存区，比如日志文件,我们就要把他们从暂存区拿出来。123456789101112131415161718192021$ git statusOn branch masterYour branch is up to date with 'origin/master'.Changes to be committed: (use "git reset HEAD &lt;file&gt;..." to unstage) new file: mysql.log $ git reset -- mysql.log$ git statusOn branch masterYour branch is up to date with 'origin/master'.Untracked files: (use "git add &lt;file&gt;..." to include in what will be committed) mysql.lognothing added to commit but untracked files present (use "git add" to track)status查看暂存区，里面有一个mysql.log被放进去了git reset -- mysql.log把mysql.log取出来status可以看到真的取出来了然后如果不要想这个文件的话再rm掉就好啦,但是如果这些文件每次自动生成都要用这种方式取出暂存区真的好累，我们可以用 git忽略不想提交的文件回滚文件到某个提交当我们想要把某个文件任意的回滚到某次提交上，而不改变其他文件的状态我们要怎么做呢？我们有两种情况，一种是，只是想在工作区有修改的文件，直接丢弃掉他现在的修改；第二种是想把这个文件回滚到以前的某一次提交。我们先来说第一种：取消文件在工作区的修改123456789101112131415161718192021222324$ cat time.txt10:41$ echo 18:51 &gt; time.txt$ git statusOn branch masterYour branch is up to date with 'origin/master'.Changes not staged for commit: (use "git add &lt;file&gt;..." to update what will be committed) (use "git checkout -- &lt;file&gt;..." to discard changes in working directory) modified: time.txtno changes added to commit (use "git add" and/or "git commit -a")$ cat time.txt18:51$ git checkout -- time.txt$ cat time.txt10:41更新time.txt的内容，可以status看到他发生了变化git checkout -- time.txt , 取消这次在工作区的修改，如果他已经被add加到了暂存区，那么这个命令就没有用了，他的意思是取消本次在工作区的修改，去上一次保存的地方。如果没有add就回到和版本库一样的状态；如果已经加到了暂存区，又做了修改，那么就回加到暂存区后的状态将文件回滚到任意的版本我们这里说的把文件回滚到以前的某个版本的状态，完整的含义是保持其他文件的内容不变，改变这个文件到以前的某个版本，然后修改到自己满意的样子和做下一次的提交。核心命令1git checkout [&lt;options&gt;] [&lt;branch&gt;] -- &lt;file&gt;...我们还是用time.txt这个文件来做试验,先搞三个版本出来，在这里我已经搞好了，来看看：版本1，time.txt内容00:501234commit 35b66ed8e3ae2c63cc4ebf323831e3b917d2b1d4 (HEAD -&gt; master, origin/master, origin/HEAD)Author: pzqu &lt;pzqu@example.com&gt;Date: Sun Dec 23 00:51:54 2018 +0800 [*]update time to 00:50版本2，time.txt内容18:511234commit 856a74084bbf9b678467b2615b6c1f6bd686ecffAuthor: pzqu &lt;pzqu@example.com&gt;Date: Sat Dec 22 19:39:19 2018 +0800 [*]update time to 18:51版本3，time.txt内容10:411234commit 3f22a0639f8d79bd4e329442f181342465dbf0b6Author: pzqu &lt;pzqu@example.com&gt;Date: Tue Dec 18 10:42:29 2018 +0800 [+]add file time.txt现在的是版本1，我们把版本3检出试试。12345678910111213$ git checkout 3f22a0639f8d -- time.txt$ cat time.txt10:41$ git statusOn branch masterYour branch is up to date with 'origin/master'.Changes to be committed: (use "git reset HEAD &lt;file&gt;..." to unstage) modified: time.txt使用checkout+commit id+-- filename的组合，横跨版本2把历史版本3的time.txt搞出来了查看状态,time.txt被改变了我们来把time.txt恢复到版本1，同样的方法，因为版本1是上一次提交我们可以省略掉版本号1234$ git checkout -- time.txt$ cat time.txt00:50看到了吧！只要用git checkout commit_id -- filename的组合，想搞出哪个文件历史版本就搞出哪个。到了这里，你可能会很懵比,reset和checkout命令真的好像啊！都可以用来做撤消checkout语义上是把什么东西取出来，所以此命令用于从历史提交（或者暂存区域）中拷贝文件到工作目录，也可用于切换分支。reset语义上是重新设置，所以此命令把当前分支指向另一个位置，并且有选择的变动工作目录和索引。也用来在从历史仓库中复制文件到索引，而不动工作目录。还想不通可以给我发邮件：pzqu@qq.com救命的后悔药来到这里我已经很清楚的你的现况了，你的代码丢了现在一定非常的着急，不要慌，总是有办法找回他们的。但是前提是要保证你的项目根目录下.git文件夹是完整的，要是手动删除了里面的一些东西那就真完了。还要保证一点，你的代码以前是有过git追踪的，最少add过找回你丢失的历史记录Git提供了一个命令git reflog用来记录你的每一次命令，贴个图吧直观点：有没有发现，git reflog里的全部都是和改变目录树有关的，比如commit rebase reset merge，也就是说一定要有改变目录树的操作才恢复的回来像add这种操作就不能恢复了吗？那肯定不是，只是要用更麻烦点的方式来恢复git log是一样的，也可以看到所有分支的历史提交，不一样的是看不到已经被删除的 commit 记录和 reset rebase merge 的操作我们可以看到git reflog前面的就是commit id，现在我们就可以用之前介绍过的方法来回滚版本了，撤消当前commit12345678910111213141516171819202122232425$ git reset --hard 856a740HEAD is now at 856a740 [*]update time to 18:51$ git log -1commit 856a74084bbf9b678467b2615b6c1f6bd686ecff (HEAD -&gt; master)Author: pzqu &lt;pzqu@example.com&gt;Date: Sat Dec 22 19:39:19 2018 +0800 [*]update time to 18:51 $ git reset --hard 35b66edHEAD is now at 35b66ed [*]update time to 00:50$ git log -2commit 35b66ed8e3ae2c63cc4ebf323831e3b917d2b1d4 (HEAD -&gt; master, origin/master, origin/HEAD)Author: pzqu &lt;pzqu@example.com&gt;Date: Sun Dec 23 00:51:54 2018 +0800 [*]update time to 00:50commit 856a74084bbf9b678467b2615b6c1f6bd686ecffAuthor: pzqu &lt;pzqu@example.com&gt;Date: Sat Dec 22 19:39:19 2018 +0800 [*]update time to 18:51根据git reflog返回的结果，用git reset --hard commit_id回退到856a740这个版本git log -1看近一行的日志，可以看到目前就在这了再根据git reflog的结果，用git reset --hard 35b66ed跑到这次提交git log -2看到两次提交的日志，我们就这么再穿梭过来了，就是这么爽但是我们如果只是想把此提交给找回来，恢复他，那还是不要用reset的方式，可以用cherry-pick或者merge来做合并找回忘记提交的历史记录你之前没有commit过的文件，被删除掉了，或者被reset --hard的时候搞没了,这种情况可以说是相当的难搞了，所幸你以前做过add的操作把他放到过暂存区，那我们来试试找回来,先来创建一个灾难现场123456789101112131415161718192021222324$ echo 'my lose message' &gt; lose_file.txt$ git add lose_file.txt$ git statusOn branch masterYour branch is up to date with 'origin/master'.Changes to be committed: (use "git reset HEAD &lt;file&gt;..." to unstage) new file: lose_file.txt$ git reset --hard 35b66ed8HEAD is now at 35b66ed [*]update time to 00:50$ git statusOn branch masterYour branch is up to date with 'origin/master'.nothing to commit, working tree clean$ lsREADME.md need_stash.txt share_file.txt time.txt创建一个叫lose_file.txt的文件并写入内容my lose message，并把他加到暂存区用git reset --hard 35b66ed8用丢弃一切修改的方式来使现在的工作区恢复到35b66ed8版本，因为还没提交所以也就是恢复到当前的（head）版本。我们用status和ls再看，这个叫lose_file.txt的文件真的没了，完蛋了,第一反应用刚刚学到的命令git reflow会发现根本就不好使核心命令：git fsck --lost-found,他会通过一些神奇的方式把历史操作过的文件以某种算法算出来加到.git/lost-found文件夹里12345678910111213$ git fsck --lost-foundChecking object directories: 100% (256/256), done.Checking objects: 100% (3/3), done.dangling blob 7f5965523d2b9e850b39eb46e8e0f7c5755f6719dangling commit fdbb19cf4c5177003ea6610afd35cda117a41109dangling commit 8be46aa83f0fe90317b0c6b9c201ad994f8caeafdangling blob 11400c1d56142615deba941a7577d18f830f4d85dangling tree 3bd4c055afedc51df0326def49cf85af15994323dangling commit 3d113a773771c09b7c3bf34b9e974a697e04210adangling commit bfdc065df8adc44c8b69fa6826e75c5991e6cad0dangling tree c96ff73cb25b57ac49666a3e1e45e0abb8913296dangling blob d6d03143986adf15c806df227389947cf46bc6dedangling commit 7aa21bc382cdebe6371278d1af1041028b8a2b09这里涉及到git的一些低层的知识，我们可以看到这里有blob、commit、tree类型的数据，还有tag等类型的。他们是什么含义呢？blob组件并不会对文件信息进行存储，而是对文件的内容进行记录commit组件在每次提交之后都会生成，当我们进行commit之后，首先会创建一个commit组件，之后把所有的文件信息创建一个tree组件,所以哪个blob代表什么文件都可以在tree 里找到我们来看看怎么恢复刚刚不见了的lose_file.txt文件，在上面执行完git fsck --lost-found命令，返回的第一行blob我们看看他的内容1234567git show 7f5965523d2b9e850b39eb46e8e0f7c5755f6719my lose messagegit show 7f5965523d2b9e850b39eb46e8e0f7c5755f6719 &gt; lose_file.txt$ lsREADME.md lose_file.txt need_stash.txt share_file.txt time.txt看到没有，就是我们丢失的文件内容，这样就找回来了！我们再来看看commit tree的内容1234567891011$ git cat-file -p fdbb19cf4c5177003ea6610afd35cda117a41109tree 673f696143eb74ac5e82a46ca61438b2b2d3bbf4parent e278392ccbf4361f27dc338c854c8a03daab8c49parent 7b54a8ae74be7192586568c6e36dc5a813ff47cfauthor pzqu &lt;pzqu@example.com&gt; 1544951197 +0800committer pzqu &lt;pzqu@example.com&gt; 1544951197 +0800Merge branch 'master' of github.com:pzqu/git_test$ git ls-tree 3bd4c055afedc51df0326def49cf85af15994323100644 blob c44be63b27a3ef835a0386a62ed168c91e680e87 share_file.txt用git cat-file -p可以看到commit的内容，可以选择把这个commit合并到我们的分支里，还是reset merge rebase cherry-pick这些命令来合commitgit ls-tree列出tree下面的文件名和id的记录信息，然后就可以根据这些来恢复文件了后记：如果你发现执行git fsck --lost-found的输出找不到你想要的，那么在执行完git fsck --lost-found后会出现一堆文件 在 .git/lost-found 文件夹里,我们不管他。可以用以下命令来输出近期修改的文件12345678910111213141516171819$ find .git/objects -type f | xargs ls -lt | sed 3q-r--r--r-- 1 pzqu staff 32 12 23 12:19 .git/objects/7f/5965523d2b9e850b39eb46e8e0f7c5755f6719-r--r--r-- 1 pzqu staff 15 12 23 01:51 .git/objects/e6/9de29bb2d1d6434b8b29ae775ad8c2e48c5391-r--r--r-- 1 pzqu staff 162 12 23 00:51 .git/objects/35/b66ed8e3ae2c63cc4ebf323831e3b917d2b1d4$ git cat-file -t 7f5965523d2b9e850b39eb46e8e0f7c5755f6719blob$ git cat-file -p 7f5965523d2b9e850b39eb46e8e0f7c5755f6719my lose message$ git cat-file -t b2484b5ab58c5cb6ecd92dacc09b41b78e9b0001tree$ git cat-file -p b2484b5ab58c5cb6ecd92dacc09b41b78e9b0001100644 blob f9894f4195f4854cfc3e3c55960200adebbc3ac5 README.md100644 blob e69de29bb2d1d6434b8b29ae775ad8c2e48c5391 need_stash.txt100644 blob 83f50ec84c00f5935da8089bac192171cfda8621 share_file.txt100644 blob f0664bd6a49e268d3db47c508b08d865bc25f7bb time.txt这里用find .git/objects -type f | xargs ls -lt | sed 3q返回了近3个修改的文件,想要更多就改3q这个数值，比如你想输出100个就用100qgit cat-file -t 7f5965523d2b9e850b39eb46e8e0f7c5755f6719 就能看见文件类型 把最后一个/去掉 复制从objects/ 后面的所有东西放在-t后面git cat-file -p id就能看见文件内容，是不是很爽漏提交有时候会碰到我们已经commit但是有修改忘记了提交，想把他们放在刚刚的commit里面，这种时候怎么做呢？1234567891011121314151617181920212223242526$ git log --name-status --pretty=oneline -135b66ed8e3ae2c63cc4ebf323831e3b917d2b1d4 (HEAD -&gt; master, origin/master, origin/HEAD) [*]update time to 00:50M time.txt$ git statusOn branch masterYour branch is up to date with 'origin/master'.Changes to be committed: (use "git reset HEAD &lt;file&gt;..." to unstage) new file: lose_file.txt new file: test_amend.txt $ git commit --amend --no-edit[master 31cc277] [*]update time to 00:50 Date: Sun Dec 23 00:51:54 2018 +0800 3 files changed, 2 insertions(+), 1 deletion(-) create mode 100644 lose_file.txt create mode 100644 test_amend.txt $ git log --name-status --pretty=oneline -131cc2774f0668b5b7c049a404284b19e9b40dc5d (HEAD -&gt; master) [*]update time to 00:50A lose_file.txtA test_amend.txtM time.txt查看文件提交日志只有time.txtstage里还有新的修改在使用git commit --amend --no-edit合并到上一个提交里，如果不加--no-edit参数的话，会提示你来修改commit提示信息(这个命令也可以用在重复编辑commit message)。查看日志，合并提交成功！tag标签创建一个tag标签是一个类似于快照的东西，常常用于测试和发布版本。所以我们常常把tag名以版本号来命名，比如：v1.0beat1这样我们怎么创建标签呢？首先先切换到想打标签的分支，然后直接打就可以了。1234567891011121314151617181920$ git branch dev/pzqu master* release_v1.0$ git tag -a release_v1.0 -m "release v1.0"$ git tag release_v1.1$ git tagrelease_v1.0release_v1.1$ git push --tagsCounting objects: 2, done.Writing objects: 100% (2/2), 158 bytes | 158.00 KiB/s, done.Total 2 (delta 0), reused 0 (delta 0)To github.com:pzqu/git_test.git * [new tag] release_v1.0 -&gt; release_v1.0 * [new tag] release_v1.1 -&gt; release_v1.1切换到想打tag的分支创建名为release_v1.0带有信息release v1.0的tag创建的不带有tag的提交信息的release_v1.1git tag查看tag推送本地全部tag也可以推送单个tag1234$ git push origin release_v1.1Total 0 (delta 0), reused 0 (delta 0)To github.com:pzqu/git_test.git * [new tag] release_v1.1 -&gt; release_v1.1我们来删除tag123456789$ git tag -d release_v1.0Deleted tag 'release_v1.0' (was eb5d177)$ git push origin :refs/tags/release_v1.0To github.com:pzqu/git_test.git - [deleted] release_v1.0$ git tagrelease_v1.1本地删除名为release_v1.0的tag远程删除名为release_v1.0的tag对历史提交打tag先看看当前的log1234531cc277 (HEAD -&gt; release_v1.0, tag: release_v1.1, origin/release_v1.0, master) [*]update time to 00:50856a740 [*]update time to 18:513f22a06 [+]add file time.txt4558a25 (origin/dev/pzqu, dev/pzqu) [*]test stashd9e018e [*]merge master to dev/pzqu比方说要对[*]update time to 18:51这次提交打标签，它对应的commit id是856a740，敲入命令：12345$ git tag v.9 856a740$ git log --pretty=oneline --abbrev-commit31cc277 (HEAD -&gt; release_v1.0, tag: release_v1.1, origin/release_v1.0, master) [*]update time to 00:50856a740 (tag: v0.9) [*]update time to 18:51成功打上git忽略不想提交的文件我们有两种情况，一种是我们根本就不想这些文件出现在git库里比如日志文件；另一种是git远程仓库里有这些文件，就像通用的配置文件，我们必须要在本地修改配置来适应运行环境，这种情况下我们不想每次提交的时候都去跟踪这些文件。忽略自动生成的垃圾文件、中间文件、敏感信息文件忽略文件的原则是：忽略操作系统自动生成的文件，比如缩略图等；忽略编译生成的中间文件、可执行文件等，也就是如果一个文件是通过另一个文件自动生成的，那自动生成的文件就没必要放进版本库，比如Java编译产生的.class文件；忽略你自己的带有敏感信息的配置文件，比如存放口令的配置文件。我们要怎么做呢？在Git工作区的根目录下创建一个特殊的.gitignore文件，然后把要忽略的文件名填进去，Git就会自动忽略这些文件。12345678910111213$ echo "*.log" &gt; .gitignore$ touch test.log$ touch test2.log$ ls -a. .git README.md need_stash.txt test.log test_amend.txt.. .gitignore lose_file.txt share_file.txt test2.log time.txt$ git statusOn branch release_v1.0nothing to commit, working tree clean创建并写入忽略规则*.log忽略全部以.log为后缀的文件创建了test.log和test2.logstatus查看，真是工作区是clean，新创建的文件没有被跟踪忽略远程存在，本地不想与远程同步的文件添加跟踪忽略核心命令：1git update-index —assume-unchanged 文件名创建time.txt文件并写入10:41,提交到远程仓库使用命令git update-index —assume-unchanged加time.txt加到忽略名单里修改time.txt的内容为10:43status查看确实没有被跟踪看远程仓库取消跟踪忽略核心命令：1git update-index —no-assume-unchanged 文件名pull同步远程仓库，真的没有更新刚刚被添加跟踪忽略的文件git update-index —no-assume-unchanged取消跟踪忽略status查看，出现文件的跟踪查看跟踪记录如果忘记了哪些文件被自己本地跟踪使用命令git update-index —assume-unchanged加time.txt加到忽略名单里使用git ls-files -v| grep &#39;^h\ &#39;命令可以看到小写h代表本地不跟踪的文件小结学完本文章，你将学会撤消commit,回滚暂存区，回滚工作区、回退远程仓库两种方法找回不小心丢失的文件提交的时候漏了文件，修改commit的提交信息tag操作，创建、创建有描述信息的tag、删除tag、删除远程tag、推送本地单个tag和全部taggit忽略自动生成的垃圾文件、中间文件、敏感信息文件；忽略远程存在，本地不想与远程同步的文件并恢复跟踪和查看哪些文件被跟踪注意事项理论上，git日常用到的命令是 diff show fetch rebase pull push checkout commit status 等，这些命令都不会导致代码丢失，假如害怕代码丢失，可以预先commit一次，再进行修改，但切记不可使用自己不熟悉的命令任何命令，不要加上-f的强制参数，否则可能导致代码丢失建议多使用命令行，不要使用图形界面操作下集引用git官网廖雪峰的官方网站-git篇hexo博客部署到vps关于git reset –hard这个命令的惨痛教训Git 基础再学习之：git checkout – file如何理解git checkout – file和git reset HEAD – file]]></content>
  </entry>
  <entry>
    <title><![CDATA[版本控制工具——Git常用操作（上）]]></title>
    <url>%2Fgit-start%2F</url>
    <content type="text"><![CDATA[摘要：用了很久的Git和svn,由于总是眼高手低，没能静下心来写这些程序员日常开发最常用的知识点。现在准备开一个专题，专门来总结一下版本控制工具，让我们从git开始。完成本系列博客的阅读以后，你将掌握git的基本概念与git的基本命令，可以在本地随心所欲的完成代码的提交撤销保存修改等操作、可以流畅的参与多人协作，本文致力于快速的入门，如果涉及到更高级的功能需要进行更深一步的学习。本文核心点：Git的基本概念一个人使用Git时的代码版本控制–（提交、拉代码、分支操作）多人合作时的代码版本控制–（合并冲突、暂存代码）什么是Git简介git是世界上目前最先进的分布式版本控制系统,致力于团队、个人进行项目版本管理，完美的解决难以比较代码、难以合并代码、难以取消修改、难以在写当前代码的过程中保存未完成的修改去修改线上版本的bug等的痛点。git是一个非常强大的工具，但作为一个git使用者来说，不用完全学习Git的知识点与命令，因为有的命令的使用频率非常的低甚至数年都不会用到，让我们来由浅入深进行学习。git的历史git是linux的创始人linus，在付费版本控制工具BitMover收回对Linux社区免费使用权利的时候，一怒之下花费两个星期的时间写出来的。（牛笔的人）开始安装git选择自己的操作系统对应的git版本安装，安装成功后运行git version后，输出git版本则安装正确。git 官方： https://git-scm.com/downloads配置用户信息使用git config命令来配置用户名和邮箱12git config --global user.name "pzqu" git config --global user.email pzqu@example.com如果用了 –global 选项，那么更改的配置文件就是位于你用户主目录下的那个，以后你所有的项目都会默认使用这里配置的用户信息。如果要在某个特定的项目中使用其他名字或者电邮，只要去掉 –global选项重新配置即可，新的设定保存在当前项目的 .git/config 文件里。使用git config user.name和git config user.email来检查是否成功，也可以直接用git config --list来列出全部git配置信息来查看创建git托管的项目假如我们创建一个项目叫make_money，先创建一个文件夹叫make_money，再使用git init命令创建git项目。1234567891011121314151617181920# pzqu @ pzqu-pc in ~/Documents/code/test [0:05:29]$ mkdir make_money# pzqu @ pzqu-pc in ~/Documents/code/test [0:06:24]$ lsmake_money# pzqu @ pzqu-pc in ~/Documents/code/test [0:06:29]$ cd make_money# pzqu @ pzqu-pc in ~/Documents/code/test/make_money [0:07:10]$ git initInitialized empty Git repository in /Users/pzqu/Documents/code/test/make_money/.git/# pzqu @ pzqu-pc in ~/Documents/code/test/make_money on git:master o [0:07:12]$ ls -altotal 0drwxr-xr-x 3 pzqu staff 96 11 7 00:07 .drwxr-xr-x 3 pzqu staff 96 11 7 00:06 ..drwxr-xr-x 9 pzqu staff 288 11 7 00:07 .git创建成功以后，会出现一个叫.git的隐藏文件夹，这个就是你的git仓库，以后所有的git操作历史提交记录信息就全部记录在此了，只要这个文件夹在就可以记住我们的全部git操作工作区和暂存区在使用git的时候还要清楚暂存区和工作区的含义，参考廖雪峰的官方网站-git篇-工作区和暂存区常见情况提交代码新文件与修改1234567891011121314151617181920212223242526# pzqu @ pzqu-pc in ~/Documents/code/test/git_test on git:master o [11:37:50]$ lsREADME.md# pzqu @ pzqu-pc in ~/Documents/code/test/git_test on git:master o [11:42:02]$ touch file1.txt# pzqu @ pzqu-pc in ~/Documents/code/test/git_test on git:master x [11:42:15]$ git add file1.txt# pzqu @ pzqu-pc in ~/Documents/code/test/git_test on git:master x [11:42:23]$ git statusOn branch masterYour branch is up to date with 'origin/master'.Changes to be committed: (use "git reset HEAD &lt;file&gt;..." to unstage) new file: file1.txt# pzqu @ pzqu-pc in ~/Documents/code/test/git_test on git:master x [11:56:38]$ git commit -m "[+]add new file1.txt"[master 66cc488] [+]add new file1.txt 1 file changed, 0 insertions(+), 0 deletions(-) create mode 100644 file1.txt上图操作包含:创建新文件file1.txtadd 添加修改的内容到索引status 查看修改的内容commit 把索引提交到本地分支git add . ：监控工作区的状态树，此命令会把工作时的所有变化提交到暂存区，包括文件内容修改(modified)以及新文件(new)，但不包括被删除的文件。git add -u：他仅监控已经被add的文件（即tracked file），他会将被修改的文件提交到暂存区。add -u 不会提交新文件（untracked file）。（git add –update的缩写）git add -A ：是上面两个功能的合集（git add –all的缩写）git show 列出最近一次的提交 对于commit：像这样，你不断对文件进行修改，然后不断提交修改到版本库里，就好比玩RPG游戏时，每通过一关就会自动把游戏状态存盘，如果某一关没过去，你还可以选择读取前一关的状态。有些时候，在打Boss之前，你会手动存盘，以便万一打Boss失败了，可以从最近的地方重新开始。Git也是一样，每当你觉得文件修改到一定程度的时候，就可以“保存一个快照”，这个快照在Git中被称为commit。一旦你把文件改乱了，或者误删了文件，还可以从最近的一个commit恢复，然后继续工作，而不是把几个月的工作成果全部丢失。删除文件12345678910111213141516171819202122232425262728# pzqu @ pzqu-pc in ~/Documents/code/test/git_test on git:master o [12:55:24]$ lsREADME.md file1.txt# pzqu @ pzqu-pc in ~/Documents/code/test/git_test on git:master o [12:55:25]$ git rm file1.txtrm 'file1.txt'# pzqu @ pzqu-pc in ~/Documents/code/test/git_test on git:master x [12:55:30]$ lsREADME.md# pzqu @ pzqu-pc in ~/Documents/code/test/git_test on git:master x [12:55:32]$ git statusOn branch masterYour branch is ahead of 'origin/master' by 1 commit. (use "git push" to publish your local commits)Changes to be committed: (use "git reset HEAD &lt;file&gt;..." to unstage) deleted: file1.txt# pzqu @ pzqu-pc in ~/Documents/code/test/git_test on git:master x [12:55:40] C:128$ git commit -m "[-]delete file1.txt"[master e278392] [-]delete file1.txt 1 file changed, 0 insertions(+), 0 deletions(-) delete mode 100644 file1.txt上图操作包含:创建新文件file1.txtgit rm 删除file1.txt文件status 查看修改的内容commit 把索引提交到本地分支tip1: 如果没有用git rm删除文件，在本地删除文件后，git add一下再提交可以达到同样的效果tip2: 要是你加班太晚，头晕不小心删除了不想删除的文件怎么办？见版本控制工具——Git常用操作（下）-后悔药拉代码方法一 pull12345678910111213# pzqu @ pzqu-pc in ~/Documents/code/test/git_test on git:master o [17:01:13]$ git pullremote: Enumerating objects: 4, done.remote: Counting objects: 100% (4/4), done.remote: Compressing objects: 100% (2/2), done.remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0Unpacking objects: 100% (3/3), done.From github.com:pzqu/git_test 5fd4d8f..7b54a8a master -&gt; origin/masterMerge made by the 'recursive' strategy. share_file.txt | 1 + 1 file changed, 1 insertion(+) create mode 100644 share_file.txt上图命令：git pull查看本地仓库变化git log上图可以看到向远程仓库pull的时候，出现了两个新的commit，commit 7b54a8ae74...的提交信息为Create share_file.txt,另一个commit fdbb19cf4c51770的提交信息为Merge branch &#39;master&#39; of github.com:pzqu/git_test。事实上主线只有一个提交，为什么会出现这种情况? 是因为pull其实会做两个操作拉远程仓库代码到本地自动与当前分支合并并生成一个合并成功的提交注意这里的第二个个步骤如果远程有人和你改了同一个文件就会出现一个冲突，这个时候git会提示你哪些文件有冲突，手动改了再提交一次就可以了。详情见合并冲突方法二 fetch我在远程修改了文件，向share_file.txt加了一行内容tom modify，此时拉代码。12345678# pzqu @ pzqu-pc in ~/Documents/code/test/git_test on git:master o [21:07:21]$ git fetch# pzqu @ pzqu-pc in ~/Documents/code/test/git_test on git:master o [21:08:43]$ git rebase origin/masterFirst, rewinding head to replay your work on top of it...Applying: [+]add new file1.txtApplying: [-]delete file1.txt上图所示有以下两个操作fetch 拉取远端代码到本地rebase 把本地代码提交基于远端分支重新replay效果如下：上图是git log所输出的提交内容，刚刚pull的时候忘记把pull自动产生的merge提交到远程，rebase的时候把本地的提交放到了远程提交之后，看起来就是一条直线，比较优雅，也是推荐的方式。同样的，如果产生了冲突，详情见合并冲突分支操作创建分支分支是多人协同最经典的地方所在，我们来创建一个分支1234567$ git checkout -b dev/pzqu origin/masterBranch 'dev/pzqu' set up to track remote branch 'master' from 'origin'.Switched to a new branch 'dev/pzqu'$ git branch* dev/pzqu mastergit checkout -b 分支名 其他分支,-b代表创建并切换到新建的分支，分支名代表新创建的分支叫什么名字，这里叫dev/pzqu ，其他分支代表基于哪一个分支来创建，这里基于远程的master分支origin/master，如果省略则代表基于当前分支git branch展示本地的分支情况，加-a参数可以展示全部的分支，包括远程分支*在分支前，指明了现在所在的分支是dev/pzqu切换分支12345678910111213141516$ git checkout -b dev/pzqu2Switched to a new branch 'dev/pzqu2'$ git branch dev/pzqu* dev/pzqu2 master$ git checkout dev/pzquSwitched to branch 'dev/pzqu'Your branch is up to date with 'origin/master'.$ git branch* dev/pzqu dev/pzqu2 master基于当前分支创建了一个新的分支并自动切换过去dev/pzqu2git checkout 已存在的分支名切换分支回到dev/pzqu删除分支1234567891011$ git branch* dev/pzqu dev/pzqu2 master $ git branch -D dev/pzqu2Deleted branch dev/pzqu2 (was 7c9be37).$ git branch* dev/pzqu master位于dev/pzqu，删除了dev/pzqu2分支合并冲突合并同一个分支的冲突（常见）为了产生一个冲突，我在另一个地方向远程仓库提交了代码，更改share_file.txt文件，加了一行内容tom add for merge，本地修改同一个文件加了一行pzqu add for merge，并提交到本地，这样一来，本地和远程仓库的同一个文件就不一样了，一会拉代码一定会产生一个冲突。效果如下：一般rebase或pull冲突的时候，都会出现提示，然后git status会出现上图图示这个时候不可以进行任何分支切换和commit操作，按照他提示进行处理git status提示哪个文件是都被修改的，both modified，然后使用编辑器修改该文件，解决冲突解决完成后，git add 添加该冲突文件git rebase –continue，并更新commit message，完成整个rebase流程我们来看看这个冲突的文件：Git用&lt;&lt;&lt;&lt;&lt;&lt;&lt;，=======，&gt;&gt;&gt;&gt;&gt;&gt;&gt;标记出不同分支的内容，我们修改如下后保存：git add再git rebase --continue后完成rebase，效果如下，再push的远程仓库即可合并不同分支的代码产生冲突关于怎么创建分支与切换分支见创建分支和切换分支,这里只讨论合并时产生的冲突的情况，我们已经基于master分支创建了一个dev/pzqu分支123$ git branch* dev/pzqu master切换到master分支，加一行master add for merge并提交，文件内容如下：123456$ cat share_file.txttom addtom modifytom add for mergepzqu add for mergemaster add for merge切换到dev/pzqu分支，向share_file.txt加入一行dev/pzqu add for merge并提交，现在share_file.txt内容如下：123456$ cat share_file.txttom addtom modifytom add for mergepzqu add for mergedev/pzqu add for merge现在两个分支的同一个文件内容不一样了，现在我们在dev/pzqu分支上进行合并：1234567891011121314151617181920212223242526272829303132$ git merge masterAuto-merging share_file.txtCONFLICT (content): Merge conflict in share_file.txtAutomatic merge failed; fix conflicts and then commit the result.# pzqu @ pzqu-pc in ~/Documents/code/test/git_test on git:dev/pzqu x [11:17:31] C:1$ git statusOn branch dev/pzquYour branch is ahead of 'origin/master' by 1 commit. (use "git push" to publish your local commits)You have unmerged paths. (fix conflicts and run "git commit") (use "git merge --abort" to abort the merge)Unmerged paths: (use "git add &lt;file&gt;..." to mark resolution) both modified: share_file.txtno changes added to commit (use "git add" and/or "git commit -a")$ cat share_file.txttom addtom modifytom add for mergepzqu add for merge&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEADdev/pzqu add for merge=======master add for merge&gt;&gt;&gt;&gt;&gt;&gt;&gt; master上图出现了一个冲突，是我们意料之中的，修改share_file.txt文件，解决此冲突：123456789101112131415161718192021$ cat share_file.txttom addtom modifytom add for mergepzqu add for mergedev/pzqu add for mergemaster add for merge$ git add share_file.txt# pzqu @ pzqu-pc in ~/Documents/code/test/git_test on git:dev/pzqu x [11:22:40]$ git commit -m "[*]merge master to dev/pzqu"[dev/pzqu d9e018e] [*]merge master to dev/pzqu# pzqu @ pzqu-pc in ~/Documents/code/test/git_test on git:dev/pzqu o [11:23:00]$ git statusOn branch dev/pzquYour branch is ahead of 'origin/master' by 3 commits. (use "git push" to publish your local commits)nothing to commit, working tree clean冲突解决也提交了，看看我们现在的分支内容：上图我们可以看到：master分支比远程origin/master分支多一次提交，dev/pzqu分支由于是基于origin/master分支，合并了master分支的提交和当前dev/pzqu分支的提交，超出本地master两个提交，致此我们把master合并到dev/pzqu的操作就完成了。通常我们开一个新的开发分支是为了在自己的分支上写代码，方便提交也不会把主线弄乱，现在我们用同样的方法将dev/pzqu合并到master分支，然后把两个分支都提交到远程。1234567891011121314151617181920212223242526272829$ git checkout masterSwitched to branch 'master'Your branch is ahead of 'origin/master' by 1 commit. (use "git push" to publish your local commits)$ git merge dev/pzquUpdating 58f047a..d9e018eFast-forward share_file.txt | 1 + 1 file changed, 1 insertion(+)$ git push origin masterTotal 0 (delta 0), reused 0 (delta 0)To github.com:pzqu/git_test.git 7c9be37..d9e018e master -&gt; master $ git push origin dev/pzquCounting objects: 9, done.Delta compression using up to 8 threads.Compressing objects: 100% (9/9), done.Writing objects: 100% (9/9), 887 bytes | 887.00 KiB/s, done.Total 9 (delta 2), reused 0 (delta 0)remote: Resolving deltas: 100% (2/2), done.remote:remote: Create a pull request for 'dev/pzqu' on GitHub by visiting:remote: https://github.com/pzqu/git_test/pull/new/dev/pzquremote:To github.com:pzqu/git_test.git * [new branch] dev/pzqu -&gt; dev/pzqu切换到master分支合并dev/pzqu到master分支master推到远程仓库如果dev/pzqu要保留，就可以推送到远程仓库。现在我们可以看到全部的分支都在一起了，强迫症都舒服了。暂存代码保存现场这种情况一般是出现在你正在完成一个功能，但是忽然线上发现了一个Bug，必须马上开一个新的分支来修复bug，但是现在的功能没写完不打算提交(commit)，现在怎么办？？不用怕暂存代码来帮助你。123456789101112131415161718192021222324252627282930313233343536373839404142$ git statusOn branch dev/pzquYour branch is up to date with 'origin/master'.Changes to be committed: (use "git reset HEAD &lt;file&gt;..." to unstage) new file: need_stash.txt modified: share_file.txt$ git stashSaved working directory and index state WIP on dev/pzqu: d9e018e [*]merge master to dev/pzqu$ git stash liststash@&#123;0&#125;: WIP on dev/pzqu: d9e018e [*]merge master to dev/pzqu$ git statusOn branch dev/pzquYour branch is up to date with 'origin/master'.nothing to commit, working tree clean//省略操作：去创建一个Bug分支，修复他并完成与主线的合并，删除Bug分支。//省略操作：切回来当前分支继续开发//下面来恢复现场$ git stash apply stash@&#123;0&#125;On branch dev/pzquYour branch is up to date with 'origin/master'.Changes to be committed: (use "git reset HEAD &lt;file&gt;..." to unstage) new file: need_stash.txtChanges not staged for commit: (use "git add &lt;file&gt;..." to update what will be committed) (use "git checkout -- &lt;file&gt;..." to discard changes in working directory) modified: share_file.txtstatus查看到有2个文件修改没有提交stash把修改放到暂存区，并生成一个idstash list列出暂存区所有内容stash apply重新把暂存区内容放到本地这里的stash apply成功的把暂存区的一次暂存恢复到了本地，但是暂存区还有会保存这次暂存，如果想删除这次暂存要用git stash drop来删除；也可以用git stash pop，恢复最后一次暂存的同时把stash内容也删了。1234$ git stash drop stash@&#123;0&#125;Dropped stash@&#123;0&#125; (bfdc065df8adc44c8b69fa6826e75c5991e6cad0)$ git stash list好了，暂存区清干净了。注意：要放到暂存区的文件一定要先通过git add加到index 小结本文阅读结束以后，我们学会了Git的基本概念，知道git的作用、历史；学会安装配置Git，使用Git创建项目托管以及工作区和暂存区的概念学会Git的本地操作，提交、拉代码、创建切换删除分支操作，多人合作时的代码版本控制，学会了不同情况下的合并冲突、暂存代码操作下集预告Git常用操作（下）我计划给大家介绍以下点：后悔药-各种后悔操作（撤消commit,回滚，回退远程仓库等）哎呀，提交的时候漏了文件tag操作git忽略不想提交的文件下集传送门：版本控制工具——Git常用操作（下）注意事项理论上，git日常用到的命令是 diff show fetch rebase pull push checkout commit status 等，这些命令都不会导致代码丢失，假如害怕代码丢失，可以预先commit一次，再进行修改，但切记不可使用自己不熟悉的命令任何命令，不要加上-f的强制参数，否则可能导致代码丢失建议多使用命令行，不要使用图形界面操作引用git官网廖雪峰的官方网站-git篇hexo博客部署到vps]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>工具</tag>
        <tag>版本控制</tag>
        <tag>git教程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql备份还原方案xtrabackup]]></title>
    <url>%2Fmysql-backup-xtrabackup%2F</url>
    <content type="text"><![CDATA[摘要：mysql当数据库过大的时候，使用mysqldump的方式进行备份是一种非常慢的操作，500G的数据就够你备份一天一夜，我发现了一种mysql快速备份的方案，它使用文件存储的方式进行备份，支持全量和增量备份，这里所写为全量方式（如果可以接受备份开始到下次恢复之间的数据丢失时使用）。xtrabackup的备份速度很快，不管有多少的数据，备份速度完全是依赖于磁盘的读写速度，还支持压缩、不打断正在执行的事务、自动实现备份检验（用mysqldump会锁表，要加上可重复读–single-transaction才不会影响线上的程序写表，但是写表后的东西在还原的时候就会丢了，这也是全量备份的痛点）特点准备mysql备份组件需要的安装包安装备份工具1. 上传并解压2. 安装rpm包3. 检查是否安装成功开始备份1. 执行命令开始备份2. 检查是否备份成功还原备份1. 事务日志应用到备份2. 恢复数据3. 设置属主属组为mysql并启动引用特点(1)备份过程快速、可靠(2)备份过程不会打断正在执行的事务(3)能够基于压缩等功能节约磁盘空间和流量(4)自动实现备份检验(5)还原速度快准备mysql备份组件需要的安装包检查服务器是centos6版本还是centos7+版本。选择安装包12centos6/percona-xtrabackup/Percona-XtraBackup-2.4.12-r170eb8c-el6-x86_64-bundle.tarcentos7/percona-xtrabackup/Percona-XtraBackup-2.4.12-r170eb8c-el7-x86_64-bundle.tar安装包可以在此下载 ： https://www.percona.com/downloads/XtraBackup/LATEST/安装备份工具以下所有操作如果是在集群下，要在一个主节点上操作，操作一次即可，启动时设置主节点为被同步节点，集群的管理我们以后再讨论。1. 上传并解压假设当前系统是centos6+,使用Percona-XtraBackup-2.4.12-r170eb8c-el6-x86_64-bundle.tar包，拷贝到系统/tmp/backup_mariadb20181127目录下(没有则创建,日期写当天)，使用tar xvf Percona-XtraBackup-2.4.12-r170eb8c-el6-x86_64-bundle.tar命令解压,你可以得到以下文件。1234567# pwd/tmp/backup_mariadb20181127# lsPercona-XtraBackup-2.4.12-r170eb8c-el6-x86_64-bundle.tarpercona-xtrabackup-24-2.4.12-1.el6.x86_64.rpmpercona-xtrabackup-24-debuginfo-2.4.12-1.el6.x86_64.rpm percona-xtrabackup-test-24-2.4.12-1.el6.x86_64.rpm2. 安装rpm包执行以下命令123rpm -ivh --force --nodeps percona-xtrabackup-24-debuginfo-2.4.12-1.el6.x86_64.rpm rpm -ivh --force --nodeps percona-xtrabackup-24-2.4.12-1.el6.x86_64.rpmrpm -ivh --force --nodeps percona-xtrabackup-test-24-2.4.12-1.el6.x86_64.rpm3. 检查是否安装成功按以下显示则安装成功1234# rpm -qa | grep perconapercona-xtrabackup-test-24-2.4.12-1.el6.x86_64percona-xtrabackup-24-2.4.12-1.el6.x86_64percona-xtrabackup-24-debuginfo-2.4.12-1.el6.x86_64开始备份1. 执行命令开始备份执行以下命令开始备份，其中/etc/my.cnf为mysql配置文件位置，10.123.2.4为mysql绑定的ip（写当前机器的ip）,user1为用户名，123456Abc为密码，/tmp/backup_mariadb20181127为备份文件所在目录，所有按实际环境填写。此处我们只备份cloud库所以--databases库就不用改动了1innobackupex --defaults-file=/etc/my.cnf --host=10.123.2.4 --databases="cloud" --use-memory=500M --user=user1 --password=123456Abc /tmp/backup_mariadb20181127如果只需要备份其中一个或多个数据库，可以加参数--databases=&quot;cloud test&quot;,其中cloud和test是库名可以使用–use-memory= (例如： 1MB, 1M, 1GB, 1G)选项加速，在不指定内存大小的情况下，默认会占用100MB的内存。2. 检查是否备份成功最后一行显示completed OK！ 则备份成功，在所执行的目录下（此处是/tmp/backup_mariadb20181127）会出现备份的文件1181127 11:56:48 completed OK!可以看到文件结构，我们此处自动生成的备份文件夹名为2018-11-27_11-52-48，是一个以时间命名的文件夹12345# ls2018-11-27_11-52-48 Percona-XtraBackup-2.4.12-r170eb8c-el6-x86_64-bundle.tar percona-xtrabackup-24-2.4.12-1.el6.x86_64.rpm percona-xtrabackup-24-debuginfo-2.4.12-1.el6.x86_64.rpm percona-xtrabackup-test-24-2.4.12-1.el6.x86_64.rpm# pwd/tmp/backup_mariadb20181127还原备份1. 事务日志应用到备份备份出的数据并不能直接使用，因为备份出的数据是不一致的，我们还需要将同时备份出的事务日志应用到备份中，才能得到一份完整、一致、可用的数据，xtrabackup称这一步操作为prepare，也就是还原数据前的”准备”工作。1innobackupex --apply-log 2018-11-27_11-52-48/在事务日志容量很大的情况下，可以使用–use-memory= (例如： 1MB, 1M, 1GB, 1G)选项加速，在不指定内存大小的情况下，默认会占用100MB的内存。输出最后如下就为正确1181127 11:56:10 completed OK!2. 恢复数据方法一、此处使用该方法，适用于备份部分数据库的方法数据目录在/data/mariadb/data，我们备份的数据库为cloud库。进入mysql命令行mysql -A，删除cloud库drop database cloud;(如果无法进入命令行则到数据目录下直接干掉cloud文件夹，集群操作的话必须通过drop或者先停止集群，确定好主从模式)执行命令1234567cd /data/mariadb/datarm ib* -frm -f cloud/etc/init.d/mysqld stop #关闭数据库cd /tmp/backup_mariadb20181127/2018-11-27_11-52-48 #进入备份目录cp ib* /data/mariadb/datacp -R cloud /data/mariadb/data方法二、先停止数据库服务/etc/init.d/mysqld stop，且对应的数据目录(此处是/data/mariadb/data)为空,如果不为空，手动删除，一般此方法针对全量备份的方法。1innobackupex --datadir=/data/mariadb/data --copy-back /tmp/backup_mariadb20181127/2018-11-27_11-52-48–copy-back：对应的目录就是我们准备好的可用数据的目录。此处为/tmp/backup_mariadb20181127/2018-11-27_11-52-48–datadir：指定的目录就是还原后数据要存放的目录，如果my.cnf设置了datadir，可以省略–datadir，执行copyback时会读取my.cnf中的配置，datadir目录必须为空目录,如果不为空，手动删除。3. 设置属主属组为mysql并启动此时我们还不能启动mysql，因为我们是使用root用户拷贝的数据，所以数据目录中的数据文件的属主属组仍然为root，我们需要将这些文件的属主属组设置为mysql。1234cd /data/mariadb/datachown -R mysql.mysql *chown -R mysql.mysql /data/mariadb/binlog/etc/inid.d/mysqld start引用Xtrabackup 安装使用xtrabackup 原理]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>备份mysql数据库</tag>
        <tag>mysql教程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[rabbitmq管理利器——rabbitmqadmin]]></title>
    <url>%2Frabbitmqadmin%2F</url>
    <content type="text"><![CDATA[摘要：在运维rabbitmq集群的过程中，发生了队列的严重堆积，我们在可以容忍mq消息丢失的情况下，使用常用的purge_queue queue命令等好长时间都清理不成功，在管理页面上直接purge导致页面卡住不动，最终都没有办法达到清理成功的效果。这个时候发现了一个python的rabbitmq管理工具，非常的好用且迅速，在此记录。如何获取rabbitmqadmin常用命令查看系统操作用户管理操作队列操作其他指定输出格式用户角色rabbitmqctl 命令参考如何获取rabbitmqadmin方法1. 直接复制出来1234567891011121314151617181920212223242526cp -a /var/lib/rabbitmq/mnesia/rabbit@localhost-plugins-expand/rabbitmq_management-3.3.5/priv/www/cli/rabbitmqadmin /usr/local/bin/rabbitmqadmin``` **方法2** 从管理页面获取1. 打开`rabbitmq_management`，访问15672管理页面，方法见&lt;a href="https://qupzhi.com/first-blog" target="_blank"&gt;rabbitmq集群的各种运维操作 4.2 打开15672网页管理端，访问mq &lt;/a&gt;2. 访问 ip:15672/rabbitmqadmin下载页面，另存为`rabbitmqadmin.py`,放到此目录：`/usr/local/bin/rabbitmqadmin`，授权`chmod +x /usr/local/bin/rabbitmqadmin`多一句废话：可以使用wget直接下载页面上的东西# 常用命令## 查看```bashrabbitmqadmin list users #查看用户列表rabbitmqadmin list vhosts #查看vhostsrabbitmqadmin list connections ###查看 connectionsrabbitmqadmin list exchanges ##查看 exchangesrabbitmqadmin list bindings ##查看 bindingsrabbitmqadmin list permissions ##查看 permissionsrabbitmqadmin list channels ##查看 channelsrabbitmqadmin list parameters ##查看 parametersrabbitmqadmin list consumers ##查看consumersrabbitmqadmin list queues ##查看queuesrabbitmqadmin list policies ##查看policiesrabbitmqadmin list nodes ##查看nodesrabbitmqadmin show overview ##查看overview系统操作用户管理操作新增一个用户12rabbitmqctl add_user Username Passwordrabbitmqadmin declare user name=wyl password=password tags=administrator删除一个用户1rabbitmqctl delete_user Username修改用户的密码1rabbitmqctl change_password Username Newpassword查看当前用户列表123rabbitmqctl list_usersrabbitmqadmin list users # 查看 usersrabbitmqadmin list users name # 查看 users的时候限制字段设置用户角色1rabbitmqctl set_user_tags User TagUser为用户名， Tag为角色名(对应于administrator，monitoring，policymaker，management，或其他自定义名称见用户角色)。也可以给同一用户设置多个角色，例如1rabbitmqctl set_user_tags hncscwc monitoring policymaker队列操作添加queue12rabbitmqadmin declare queue name=test durable=true ## durable=true 代表持久化打开 declare是宣布的意思rabbitmqadmin --vhost=test --username=admin --password=admin declare queue name=test durable=true #指定vhost添加队列查看queues123[root@rabbitmq1 sbin]# rabbitmqadmin list queues#查看bindings[root@rabbitmq1 sbin]# rabbitmqadmin list bindings添加消息到test queue1rabbitmqadmin publish routing_key=test payload="this is a testing" ##未指定exchange默认 exchange name为空再次查看对列发现test有一条消息1[root@rabbitmq1 sbin]# rabbitmqadmin list queues从test queue消费一条信息1rabbitmqadmin get queue=test requeue=true #requeue=true 这条消息消费后还在，反之如果为false消费后消息就不在了。删除队列1rabbitmqadmin delete queue name=test清除队列消息内容1rabbitmqadmin purge queue name=队列名其他指定输出格式使用 -f 可以指定格式有如下几种格式 raw_json, long, pretty_json, kvp, tsv, table, bash 默认为 table,具体自己试用户角色超级管理员(administrator)可登陆管理控制台(启用management plugin的情况下)，可查看所有的信息，并且可以对用户，策略(policy)进行操作。监控者(monitoring)可登陆管理控制台(启用management plugin的情况下)，同时可以查看rabbitmq节点的相关信息(进程数，内存使用情况，磁盘使用情况等)策略制定者(policymaker)可登陆管理控制台(启用management plugin的情况下), 同时可以对policy进行管理。但无法查看节点的相关信息(上图红框标识的部分)。与administrator的对比，administrator能看到这些内容普通管理者(management)仅可登陆管理控制台(启用management plugin的情况下)，无法看到节点信息，也无法对策略进行管理。其他无法登陆管理控制台，通常就是普通的生产者和消费者。了解了这些后，就可以根据需要给不同的用户设置不同的角色，以便按需管理。rabbitmqctl 命令1234567891011121314151617181920212223242526272829303132333435rabbitmqctl list_queues：查看所有队列信息rabbitmqctl stop_app：关闭应用（关闭当前启动的节点）rabbitmqctl start_app：启动应用，和上述关闭命令配合使用，达到清空队列的目的rabbitmqctl reset：从管理数据库中移除所有数据，例如配置过的用户和虚拟宿主, 删除所有持久化的消息（这个命令要在rabbitmqctl stop_app之后使用）rabbitmqctl force_reset：作用和rabbitmqctl reset一样，区别是无条件重置节点，不管当前管理数据库状态以及集群的配置。如果数据库或者集群配置发生错误才使用这个最后的手段rabbitmqctl status：节点状态rabbitmqctl add_user username password：添加用户rabbitmqctl list_users：列出所有用户rabbitmqctl list_user_permissions username：列出用户权限rabbitmqctl change_password username newpassword：修改密码rabbitmqctl add_vhost vhostpath：创建虚拟主机rabbitmqctl list_vhosts：列出所有虚拟主机rabbitmqctl set_permissions -p vhostpath username ".*" ".*" ".*"：设置用户权限rabbitmqctl list_permissions -p vhostpath：列出虚拟主机上的所有权限 rabbitmqctl clear_permissions -p vhostpath username：清除用户权限rabbitmqctl -p vhostpath purge_queue blue：清除队列里的消息rabbitmqctl delete_user username：删除用户rabbitmqctl delete_vhost vhostpath：删除虚拟主机未完待续-催更 pzqu@qq.com参考通过rabbitmqadmin管理rabbitmq,【吴业亮】云计算开发工程师RabbitMQ学习笔记四：RabbitMQ命令（附疑难问题解决）]]></content>
      <categories>
        <category>rabbitmq</category>
      </categories>
      <tags>
        <tag>rabbitmq集群</tag>
        <tag>工具</tag>
        <tag>rabbitmq工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[rabbitmq之Federation配置]]></title>
    <url>%2Frabbitmq-federation%2F</url>
    <content type="text"><![CDATA[摘要：当我们有多个rabbitmq集群的时候，如果想要单向的同步集群的消息，也就是说把新集群当作老集群的镜像集群，实时的同步老集群的消息，在老集群消息被消费的时候不会影响同步到新集群的消息。在外部看上去就像每次写入消息的时候，同时向新老两个集群写入一样,不论mq的跨版本，不论mq的用户。一般我们会将这种情况应用于存在两个不同的系统，但是老数据来源只能向一个队列写入数据，此时为了在新系统上也可以实时同步到老系统队列中的数据的时候。Federation介绍特点松耦合性（Loose coupling）WAN 友好性（WAN-friendly）扩展性（Scalability）federation能做什么？配置的种类身份验证操作步骤说明1. 在集群的每一个node开启federation插件(同步和被同步集群都需要)2. 登录到同步集群的管理界面::http://x.x.x.:15672/#/3. 创建upstream4. 创建policy5. 查看状态图6. 查看连接高级参考Federation介绍federation 插件的最终目标是，在不同 broker 之间进行消息传递而无需建立集群；该功能在很多场景下非常有用：注意:当你在一个cluster中使用federation插件，所有在集群中 的nodes都需要安装federation插件特点松耦合性（Loose coupling）federation 插件能够在分属不同管理域的 broker 或 cluster 之间传递消息：他们可能设置了不同的 user 和 vhost ；他们可能运行在不同版本的 RabbitMQ 和 Erlang 上；WAN 友好性（WAN-friendly）federation 插件基于 AMQP 0-9-1 协议在不同 broker 之间进行通信，并设计成能够容忍不稳定的网络连通情况；扩展性（Scalability）federation 不需要在 n 个 broker 之间建立 O(n^2) 个连接（尽管这是最简单的使用模式），这也就意味着 federation 在使用时更容易扩展federation能做什么？federation 插件允许你将多个 exchange 或多个 queue 进行 federate ；federated exchange 或 federated queue 能够从一个或多个 upstream 接收到消息；也就是说，你的队列可以和其他集群的队列建立一种关系，他们之间可以相互的同步数据，可以是我同步给你，也可以是你同步给我，不过这种关系有两个角色一个是上游一个是下游，数据流向是上游流向下流。这里有三个名词，federation 插件允许你将多个 exchange 或多个 queue 进行 federate：upstream： 上游，是指位于其他 broker 上的、远端 exchange 和 queue ；federated exchange： 到exchange的关系，能够将发给 upstream 的消息路由到本地的某个 queue 中；federated queue： 到queue的关系，则允许一个本地消费者接收到来自 upstream queue 的消息；配置的种类关于 federation upstream 的信息全都保存在 RabbitMQ 的数据库中，其中包括了 user 信息、permission 信息、queue 信息等等；在 federation 中存在 3 种界别的配置：Upstreams - 每一个 upstream 用于定义如何与另外的 broker 建立连接；Upstream sets - 每一个 upstream set 用于针对一系列使用 federation 功能 upstream 进行了分组；Policies - 每一种 policy 会限定（过滤）出一组 exchange ，或者一组 queue ，或者同时针对两者进行限定；policy 最终将作用于一个单独的 upstream 上，或者一个 upstream set 上，并对其他对象发挥作用；实际上，在最简单的使用情况下，你可以忽略已经存在的upstream设置，因为有一个隐含的默认upstream叫做“all”，他会添加所有的upstream。身份验证我们讨论的是免身份验证的方式，如果有身份难的需求请参考官网：http://www.rabbitmq.com/authentication.html操作步骤说明parameter 和 policy 可以通过 3 种方式进行设置：通过 rabbitmqctl 脚本；通过 management 插件提供的 HTTP API ；通过 rabbitmq_federation_management 插件提供的 Web UI（更通用的方式,我们也是通过页面来配置就可以了）；注意：基于 Web UI 的方式不能提供全部功能，尤其无法针对 upstream set 进行管理；1. 在集群的每一个node开启federation插件(同步和被同步集群都需要)参考命令：12rabbitmq-plugins enable rabbitmq_federationrabbitmq-plugins enable rabbitmq_federation_management2. 登录到同步集群的管理界面::http://x.x.x.:15672/#/3. 创建upstreamtips:在下游，也就是新队列（被同步队列）上操作12UI操作:Admin-&gt;Federation Upstreams-&gt;Add a new upstream Name:随意填写 URI:填被同步集群(例如:amqp://user1:xxx@x.x.x.x,xxx为连接密码) Expires:默认填写3600000 单位ms其余字段可不用填写Expires：是代表缓存时间，如果说网络连通性不好的时候，消息会在上游的队列中缓存的时间，超时丢弃，设置为空则表示，永远缓存不会丢弃数据（但是如果长时候不恢复内存会占用越来越大，建议设置上）Acknowledgement Mode: 代表消息确认方式，用来防止消息在传输过程中丢失，有三个值，on-confirm、on-publish、no-ack，对传输速度的影响是从慢速到快速，对安全性是不会丢失到可能会丢失。通常使用on-publish，不然on-confirm太慢了。4. 创建policytips:在下游，也就是新队列（被同步队列）上操作1234UI操作:Admin-&gt;Policies-&gt;Add / update a policyName:随意填写(sync_data)Pattern:匹配表达式(例如:^(?!amq.).* 剔除系统队列后的所有队列)Apply to: 默认选择Exchange and queues Definition:federation-upstream-set = all (选定federation规则)5. 查看状态图现在，所有内置的 exchange 都应该建立了 federation ，因为他们都能匹配上面的 policy，可以通过页面查看状态12UI操作:Admin &gt; Federation Status &gt; Running Links 查看针对每个 exchange 的 federation 连接。配置成功可以看到匹配的Exchange / Queue， state:running也可以通过下面的命令查看状态图：1rabbitmqctl eval 'rabbit_federation_status:status().'也可以通过 management 插件中的 exchange 列表，或者下面的命令输出，确认上述 policy 已经作用到了 exchange 上；1rabbitmqctl list_exchanges name policy | grep federate-me通常情况下，针对每个 upstream 都会有一条 federation 连接，该 federation 连接对应到一个 exchange 上；例如 3 个 exchange 与 2 个 upstream 分别建立 federation 的情况下，会有 6 条连接。6. 查看连接登录到被同步集群（上游）的管理界面::http://x.x.x.:15672/#/ 前往 Connections选项 配置成功可以看到来自同步集群的连接 高级更复杂的配置：https://www.rabbitmq.com/federation-reference.html参考官网]]></content>
      <categories>
        <category>rabbitmq</category>
      </categories>
      <tags>
        <tag>rabbitmq集群</tag>
        <tag>rabbitmq教程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ansible_roles]]></title>
    <url>%2Fansible-roles%2F</url>
    <content type="text"><![CDATA[摘要：本节主要总结ansiblerroles中常用的语法以及高级特性、例如变量、下载、解压、修改文件内容等,便于使用ansible协同开发，做更加庞大的任务。常用远程执行脚本设置某个参数供下文使用文件是否存在和变量是否声明解压下载修改文件内容，直接替换方式配置文件执行命令时指定脚本执行目录高级委托统一目录结构引用常用远程执行脚本脚本放到template里12345678910- name: init rbac rights template: src: 'init_rbac_privilege.sh' dest: '/tmp/init_rbac_privilege.sh' mode: 0755- name: init rbac rights shell: "bash /tmp/init_rbac_privilege.sh" run_once: true ignore_errors: yes脚本放files文件里12345678- name: copy script file to remote server copy: src: "generate_uuid.py" dest: "&#123;&#123; dest_script_file &#125;&#125;" mode: 0755- name: set to execute script file and args shell: "python &#123;&#123; dest_script_file &#125;&#125;"设置某个参数供下文使用123456789- name: set to execute script file path set_fact: dest_script_file: '/tmp/generate_uuid.py'- name: copy script file to remote server copy: src: "generate_uuid.py" dest: "&#123;&#123; dest_script_file &#125;&#125;" mode: 0755文件是否存在和变量是否声明12345678- stat: path: "&#123;&#123; dest_script_file &#125;&#125;" register: file_result- name: set to execute script file and args shell: "python &#123;&#123; dest_script_file &#125;&#125; &#123;&#123; inventory_hostname &#125;&#125;" register: p_new_host_uuid when: host_uuid is not defined and file_result.stat.exists解压解压tar.gz，desc所指定的目录需要提前创建12345- name: Unarchive ceph_report program package unarchive: remote_src: yes src: "/tmp/ceph_report/ceph_report.tar.gz" dest: "/data/monitorcloud/script/"下载12345- name: download ceph_report package get_url: url: "http://&#123;&#123; tstack_repo_address &#125;&#125;:&#123;&#123; tstack_repo_port &#125;&#125;/tstack/tstack-tars/ceph_report.tar.gz" dest: "/tmp/ceph_report/ceph_report.tar.gz" mode: 0644修改文件内容，直接替换方式1234567891011- name: insert mons connect message lineinfile: path: "/data/monitorcloud/script/ceph_report/host_dic" state: present insertafter: EOF backrefs: no line: "&#123;&#123;item[0]&#125;&#125; &#123;&#123;item[1]&#125;&#125;" with_nested: - "&#123;&#123; groups['mons'] | union( groups['osds'] )&#125;&#125;" - ["&#123;&#123;ansible_ssh_pass&#125;&#125;"] ignore_errors: true配置文件ansible中指定配置文件，.j2中可映射ansible变量12345- name: Prepare ceph_report_http program configuration file template: src: "opts.py.j2" dest: "/data/monitorcloud/script/ceph_report/opts.py" mode: 0644执行命令时指定脚本执行目录12345- name: execute ceph_report_http install script shell: "/usr/bin/python ceph_report_http.py install" args: chdir: '/data/monitorcloud/script/ceph_report/' ignore_errors: yes高级委托在当前运行ansible的机器上，委托其他机器运行123- name: add host record to center server shell: 'echo "192.168.1.100 test.xyz.com " &gt;&gt; /etc/hosts' delegate_to: 192.168.1.1也可以委托ansible服务端运行123- name: add host record to center server shell: 'echo hello' delegate_to: localhost统一目录结构1234567891011121314151617181920212223242526272829303132project/├── filter_plugins # 自定义 filter 插件存放目录├── fooapp # Fooapp 片色目录 ( 与 common 角色目录平级)├── group_vars │ ├── group1 # group1 自定义变量文件│ └── group2 # group2 自定义变量文件├── host_vars│ ├── hostname1 # hostname1 自定义变量文件│ └── hostname2 # hostname1 自定义变量文件├── library # 自定义模块存放目录├── monitoring # Monitoring 角色目录 ( 与 common 角色目录平级)├── roles # Role 存放目录│ └── common # common 角色目录│ ├── defaults │ │ └── main.yml # common 角色自定义文件 (优先级低)│ ├── files│ │ ├── bar.txt # common 角色 files 资源文件│ │ └── foo.sh # common 角色 files 资源文件│ ├── handlers│ │ └── main.yml # common 角色 handlers 入口文件│ ├── meta│ │ └── main.yml # common 角色 依赖文件│ ├── tasks│ │ └── main.yml # common 角色 task 入口文件│ ├── template│ │ └── ntp.conf.j2 # common 角色 template 文件│ └── vars│ └── main.yml # common 角色 变量定义文件├── site.yaml # Playbook 统一入口文件├── stage # stage 环境的 inventory 文件├── webservers.yml # 特殊 Playbook 文件└── webtier # webtier 角色目录 ( 与 common 角色目录平级)引用ansible进阶技巧 https://www.ibm.com/developerworks/cn/linux/1608_lih_ansible/index.htmlshilei ansible 文档 https://wiki.shileizcc.com/confluence/display/AN/Ansible骏马金龙 ansible系列文章 http://www.cnblogs.com/f-ck-need-u/p/7576137.html#ansible]]></content>
      <categories>
        <category>ansible</category>
      </categories>
      <tags>
        <tag>自动化</tag>
        <tag>部署</tag>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[进入自动化部署的大门-ansible]]></title>
    <url>%2Fansible%E5%88%9D%E6%8E%A2%2F</url>
    <content type="text"><![CDATA[摘要：ansible是运维与实施人员的福音，其优雅的结构，丰富的模块库，简单的编程方式都让其成为自动化部署的不二语言。现在就让我们了解ansible,并使用ansible来做一些简单的任务一、基本概念1.1 如何安装及安装要求1.2 专有名词解释1.3 原理图1.4 连接机制1.5 常用文件及配置位置二、简单的例子2.1 配置被管控机器的连接信息2.2 执行命令2.3 讨论执行命令的四个模块有什么区别三、 完成复杂的ansible操作引用资源一、基本概念Ansible是一款开源软件，可自动执行软件供应，配置管理和应用程序部署。Ansible通过SSH，远程PowerShell或其他远程API连接。—-选自wikipedia简介：ansible有两种服务器类型，控制机器与节点。控制机器就是安装ansible服务的机器，我们在上面编写和运行ansible的程序代码，并在控制机器上通过ssh远程操作机器（下发上传、执行命令）。当ansible脚本不运行的时候，不会占用任何资源（比如saltstack在运行的时候就会启动进程来监控4505/4506端口），也正由于ansible的这个特点，每次ansible发布更新的时候，只需要更新控制机器就可以了。1.1 如何安装及安装要求要求：控制机是linux系统，需要有python2.6/2.7linux系统打开文件数量设置大一些（方法自行百度）节点要求，python2.4以上版本安装方法（有很多，在此只列出常用的方法，具体安装步骤不做赘述）：源码安装 git://github.com/ansible/ansible.gityum 方式 / apt 方式 / emerge 方式 或其他linux系统的系统安装方式pip 方式1.2 专有名词解释关键字释义playbook剧本，将要执行的步骤全部放到playbook里面modules（通常指core modules）核心模块，用于执行某些任务的已有内置插件roles角色，像演戏一样，剧本中指定在什么时候哪个角色来做什么操作，所以剧本包含角色，角色就有自己的台词，不过ansible里面的角色特殊的地方是，剧本只知识角色是干什么的，具体操作步骤是在角色本身管理（无厘头）custom modules自定义模块，在核心模块不够用的时候可以自定义编写模块plugins插件，常用于ansible的日志系统与邮件系统，还有的插件有扩展内置连接方式、扩展变量定义方式、扩展内部循环语法、扩展新的过滤器等InventoryAnsible 管理主机的清单1.3 原理图1.4 连接机制ansible通常使用的是ssh协议（或者Kerberos、LDAP）来进行连接（在openssh不支持的操作系统或ansible比较老的版本，ansible使用paramiko），ansible支持的连接方式有三种SSH、Local、ZeroMQ，在规模比较大的情况下使用ZeroMQ连接方式对执行速度有显著提高1.5 常用文件及配置位置文件位置ansible应用程序的主配置文件/etc/ansible/ansible.cfg定义管控主机/etc/ansible/hosts二、简单的例子这里我们来实现在所有被管控机器上执行hostname命令输出主机名2.1 配置被管控机器的连接信息备注1：在/etc/ansible/hosts位置写入一个主机组（分组名为test），以后针对这个分组操作就视为对分组内的所有主机操作。备注2：[test:vars] 标签下为test分组的变量，ansible_ssh_user和ansible_ssh_pass是ansible的内置变量，意思为该分组下所有主机的用户和和密码，当前了也可以单独指定某台主机只需要将这两个参数追加到ip的旁边就好。这里三台主机都是同一个用户名和密码，所以像这样配置。备注3：默认路径是在/etc/ansible/hosts,如果你不喜欢是可以修改的(修改配置文件/etc/ansible/ansible.cfg的inventory=/etc/ansible/hosts即可)2.2 执行命令执行命令，输出test分组下的所有主机的主机名，-i指定主机或分组,-m指定使用的模块，-a指定传给模块的参数，这里command模块就是执行linux命令的模块缺省时默认使用该模块，相同作用的还有shell模块、raw模块、script模块（使用场景与部分细节上不同，后面探讨）2.3 讨论执行命令的四个模块有什么区别每次在使用的时候都会有一些迷惑，为什么非要弄四个执行命令的模块出来，一开始决定没有必要，但是到后来才明白存在既合理，这里和大家探讨一下模块解释command模块是为了安全的执行linux命令，所以不支持`”&lt;”, “&gt;”, ““, 和 “&amp;”`等符号（没有shell注入风险），如果要一定要使用这些，则使用shell模块shell模块通过/bin/sh来执行，其他都和command一样raw模块用来执行低版本的linux命令，可以不需要python来执行命令，甚至支持windows命令，带来的问题是很多很特性是不能用的script模块其原理是先将脚本，复制到远程主机，再在远程主机上执行，所以要指定脚本路径以及操作方法结论：要安全用command，要方便用shell，要操作写好的shell脚本或者其他脚本就用script、要是以上操作都跑不了的机器就用raw三、 完成复杂的ansible操作未完待续–引用Ansible插件扩展 https://blog.csdn.net/yongchaocsdn/article/details/79271870资源插件 https://github.com/ansible/ansible/tree/stable-2.4/lib/ansible/plugins]]></content>
      <categories>
        <category>ansible</category>
      </categories>
      <tags>
        <tag>自动化</tag>
        <tag>部署</tag>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[配置像我一样的hexo博客]]></title>
    <url>%2F%E9%85%8D%E7%BD%AE%E5%83%8F%E6%88%91%E4%B8%80%E6%A0%B7%E7%9A%84hexo%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[摘要：csdn和博客园虽然用的人多、技术氛围好，但是由于csdn的广告和灌水以及博客园的简陋页面让我决定搭建一套属于自己的博客，此处用到比较火的hexo搭建，而且免费就能获得自己的网站，如果不买域名的话完全够用了一、搭建本地 hexo1.1 安装nodejs1.2 安装git1.3 使用npm安装Hexo1.4 创建本地服务1.5 主题配置二、 配置你的github2.1 创建一个新项目2.2 填写正确的项目名称2.3 配置你的项目三、激动人心的博客3.1 修改hexo配置文件3.2 部署成功四、个性化配置你的博客4.1 配置博客名，博客描述等信息4.2 添加头像4.3 添加日志列表4.2 其他五、配置你的hexo可以插入图片附：加速npm引用一、搭建本地 hexo1.1 安装nodejs到nodejs官网下载安装 http://nodejs.cn/1.2 安装git到git官网下载安装 https://git-scm.com/downloads1.3 使用npm安装Hexo1npm install -g hexo-cli备注： 如果npm下载比较慢可以跳到 附：加速npm1.4 创建本地服务创建一个文件夹，此处为blog，执行以下命令1234hexo i blog //init的缩写 blog是项目名cd blog //切换到站点根目录hexo g //generetor的缩写hexo s //server的缩写访问本地服务localhost:4000证明成功,为什么和我的不一样，因为我修改了hexo的主题配置可以跳到 四、个性化配置你的博客有页面出来证明你的配置已经成功了，原始的主题不是很喜欢，我这里也使用了最火的nexT主题1.5 主题配置在站点根目录输入1git clone https://github.com/iissnan/hexo-theme-next themes/next完成后，打开根目录下的_config.yml， 找到 theme 字段，并将其值更改为 nextnext有三种主题，我选择的是双栏 Scheme，找到 站点根目录/themes/next/_congig.yml 文件，再找到schme字段，将其值改为Pisces,其他两种可以参考引用里所写的使配置生效123hexo clean //清除缓存hexo g //重新生成代码hexo s //部署到本地这样你的会有一套和我一样主题的博客了，如果你不喜欢这套主题，或者想自己来开发一套定制自己的主题参考官方文档,下面让我们把他推到github上，变成独一无二的网站二、 配置你的github2.1 创建一个新项目如果没有注册github帐号到&gt;官网注册点此创建项目（如果你不是程序员建议勾选上图中Initalize this repository with a README选项）：2.2 填写正确的项目名称项目名可以为任意英文.github.io，public设置为公开项目,点击绿色创建按钮2.3 配置你的项目在项目里创建一个readme.md即可，这下可以在页面上访问到这个免费的网站了我的网站 https://pzqu.github.io/三、激动人心的博客3.1 修改hexo配置文件修改根目录的配置文件_config.yml，以下部分如果没有需要手动创建，建议直接拷贝我的，repo为自己刚刚创建的那个项目的git链接（注意冒号与值之间必须有空格）1234deploy: type: git repo: https://github.com/pzqu/pzqu.github.io.git branch: master3.2 部署成功直接执行一套命令,再刷新刚刚的域名即可12npm install hexo-deployer-git --savehexo d // 部署的命令,会生成代码并推送到github上去四、个性化配置你的博客4.1 配置博客名，博客描述等信息参考官方网站 https://hexo.io/zh-cn/docs/configuration.html4.2 添加头像在主题配置文件里修改avatar: images/avatar.gif4.3 添加日志列表4.2 其他添加顶部加载条,修改主题配置文件，pace_theme有好几款，自己选一款12pace: truepace_theme: pace-theme-flash添加打赏功能，修改主题配置文件，图片可以上传到themes\next\source\images123reward_comment: 坚持原创技术分享，您的支持将鼓励我继续创作！wechatpay: /images/wxpay.jpgalipay: /images/alipay.jpg文章阅读量参考 https://www.jianshu.com/p/702a7aec4d00评论系统http://www.zhaojun.im/hexo-valine/删除底部强力驱动、统计站点网上自己查添加分享添加评论五、配置你的hexo可以插入图片把主页配置文件 _config.yml 里的post_asset_folder:这个选项设置为true在你的hexo目录下执行npm install hexo-asset-image --save等待一小段时间后，再运行hexo n &quot;配置像我一样的hexo博客&quot;来生成md博文时，/source/_posts文件夹内除了配置像我一样的hexo博客.md文件还有一个同名的文件夹最后在配置像我一样的hexo博客.md中想引入图片时，先把图片复制到配置像我一样的hexo博客这个文件夹中，然后只需要在配置像我一样的hexo博客.md中按照markdown的格式引入图片,注意使用相对路径：![你想输入的替代文字](配置像我一样的hexo博客/图片名.jpg)附：加速npm配置npm镜像npm config set registry https://registry.npm.taobao.org查看npm镜像npm config get registry引用用Hexo + github搭建自己的博客 — 再也不用羡慕别人了！npm太慢， 淘宝npm镜像使用方法]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>建站教程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[rabbitmq集群的各种运维操作]]></title>
    <url>%2Ffirst-blog%2F</url>
    <content type="text"><![CDATA[摘要：在rabbitmq集群操作或者搭建的时候，常常会因为对于集群的不熟练而导致各种异常错误，常见的有绑定了浮动ip没有绑定实体ip导致，页面上操作mq完全没有问题，但是一到程序操作就出现问题，我们一起来学习下，rabbitmq集群的正确操作一、rabbitmq集群必要条件1.1. 绑定实体ip，即ifconfig所能查询到的绑定到网卡上的ip,以下是绑定方法1.2. 配置域名映射到实体ip二、启动停止2.1 停止2.2 启动三、重建集群3.1 使用2.1方法停止所有机器3.2 移除rabbitmq配置记录与存储文件3.3 按2.2方法启动所有机器3.4 停止被加入集群节点app3.5 建立集群3.6 启动集群3.7 检查集群状态3.8 添加集群配置 （见第四）四 添加集群配置4.1 创建用户4.2 打开15672网页管理端，访问mq4.3 在底部导入.json后缀的配置文件即可以下操作都以三节点集群为例，机器名标记为机器A、机器B、机器C，如果为双节点忽略机器C，如果为各多节点则与机器C操作相同一、rabbitmq集群必要条件1.1. 绑定实体ip，即ifconfig所能查询到的绑定到网卡上的ip,以下是绑定方法12#编辑配置路径 /etc/rabbitmq/rabbitmq-env.confNODE_IP_ADDRESS=172.16.136.1331.2. 配置域名映射到实体ip123456789101112131415161718192021#配置文件1所在路径 /etc/rabbitmq/rabbitmq.config (如果是集群，每台机器都需要修改这个绑定本机实体ip)#其中rabbit@master是创建集群时所配置的参数，@后面的参数为主机名，示例中为master[ &#123;rabbit, [ &#123;cluster_nodes, &#123;[&apos;rabbit@master&apos;], disc&#125;&#125;, &#123;cluster_partition_handling, ignore&#125;, &#123;default_user, &lt;&lt;&quot;guest&quot;&gt;&gt;&#125;, &#123;default_pass, &lt;&lt;&quot;guest&quot;&gt;&gt;&#125;, &#123;tcp_listen_options, [binary, &#123;packet, raw&#125;, &#123;reuseaddr, true&#125;, &#123;backlog, 128&#125;, &#123;nodelay, true&#125;, &#123;exit_on_close, false&#125;, &#123;keepalive, true&#125;]&#125; ]&#125;, &#123;kernel, [ &#123;inet_dist_listen_max, 44001&#125;, &#123;inet_dist_listen_min, 44001&#125; ]&#125;].1234#配置文件2 所在路径 /etc/hosts (如果是集群，每台机器都需要修改这个绑定本机实体ip，而且hosts文件的映射不得重复，如果重复linux系统为以最下面一条记录为准)172.16.136.133 master172.16.136.134 venus172.16.136.135 venus2二、启动停止2.1 停止123456789#机器Aservice rabbitmq-server stopepmd -kill#机器Bservice rabbitmq-server stopepmd -kill#机器Cservice rabbitmq-server stopepmd -kill2.2 启动123456#机器Aservice rabbitmq-server start#机器Bservice rabbitmq-server start#机器Cservice rabbitmq-server start三、重建集群注1：此处的mq集群重建是比较快速和有效的方法，面向的是初次安装或者可以接受mq中所存有的数据丢失的情况下，必须先有mq的.json后缀的配置文件或者有把握写入集群中exchange、queue等配置。注2:如果是运行中的mq出现问题，需要在保存数据和配置的情况下恢复集群时，请跳到rabbitmq集群恢复3.1 使用2.1方法停止所有机器3.2 移除rabbitmq配置记录与存储文件12#位于 /var/lib/rabbitmq/mensiamv /var/lib/rabbitmq/mensia /var/lib/rabbitmq/mensia.bak3.3 按2.2方法启动所有机器3.4 停止被加入集群节点app比如A、B、C三台机器，将B和C加入到A中去，需要执行以下命令1234#机器Brabbitmqctl stop_app#机器Crabbitmqctl stop_app3.5 建立集群注意此处master为唯一没有执行rabbitmqctl stop_app的机器1234#机器Brabbitmqctl join_cluster rabbit@master#机器Crabbitmqctl join_cluster rabbit@master3.6 启动集群1234#机器Brabbitmqctl start_app#机器Crabbitmqctl start_app3.7 检查集群状态在任意一台机器上执行rabbitmqctl cluster_status命令即可检查，输出包含集群中的节点与运行中的节点，兼以主机名标志3.8 添加集群配置 （见第四）四 添加集群配置4.1 创建用户例子中创建了两个用户添加用户add_user,设置角色set_user_tags,添加rabbitmq虚拟主机add_vhost，设置访问权限set_permissions,以下是详细用法123456789# 创建第一个用户/usr/sbin/rabbitmqctl add_user 用户名 密码/usr/sbin/rabbitmqctl set_user_tags 用户名 administrator/usr/sbin/rabbitmqctl set_permissions -p / 用户名 ".*" ".*" ".*"# 创建第二个用户/usr/sbin/rabbitmqctl add_user 用户名2 密码/usr/sbin/rabbitmqctl set_user_tags 用户名2 management /usr/sbin/rabbitmqctl add_vhost sip_ext /usr/sbin/rabbitmqctl set_permissions -p sip_ext 用户名2 '.*' '.*' '.*'备注：RabbitMQ 虚拟主机，RabbitMQ 通过虚拟主机（vhost）来分发消息。拥有自己独立的权限控制，不同的vhost之间是隔离的，单独的。 权限控制的基本单位：vhost。 用户只能访问与之绑定的vhost。 vhost是AMQP中唯一无法通过协议来创建的基元。只能通过rabbitmqctl工具来创建。 4.2 打开15672网页管理端，访问mq/usr/sbin/rabbitmq-plugins enable rabbitmq_management备注：如果发现命令执行完毕没有打开此服务，15672端口没有监听，则是由于没有重启mq导致的4.3 在底部导入.json后缀的配置文件即可如果覆盖了用户需要使用以下命令修改mq用户密码/usr/sbin/rabbitmqctl change_password 用户名 密码]]></content>
      <categories>
        <category>rabbitmq</category>
      </categories>
      <tags>
        <tag>rabbitmq集群</tag>
        <tag>rabbitmq教程</tag>
      </tags>
  </entry>
</search>
